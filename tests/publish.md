# cs.AI
|   arxiv_id | english_title                                                                                                                            | chinese_title                                  | chinese_abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | worth_read   | comment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | download_url                     |
|-----------:|:-----------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------|
|    2511.2  | Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder                                          | 利用可穿戴设备改进阿片类药物使用障碍患者的慢性疼痛治疗                    | 慢性疼痛（CP）和阿片类药物使用障碍（OUD）是常见且相互关联的慢性疾病。目前，对于正在接受阿片类药物替代治疗（MOUD）的患者，缺乏基于循证医学的CP与OUD一体化治疗方案。可穿戴设备可以持续监测复杂的患者信息，为OUD与CP患者的治疗开发提供支持，例如监测疼痛波动（如疼痛加重或疼痛峰值）及其临床相关因素（如感知压力等）。然而，将可穿戴设备数据与大语言模型（LLM）结合，用于理解疼痛峰值的研究尚未展开。本试点研究旨在利用多种人工智能方法，考察疼痛峰值的临床相关因素。研究发现，传统机器学习模型在预测疼痛峰值方面取得了较高精度（准确率大于0.7），而LLM在提供与疼痛峰值相关的洞见方面表现有限。结果表明，基于可穿戴设备的实时监测结合先进AI模型，有望实现对疼痛峰值的早期检测，并支持个性化干预，从而降低阿片复发风险、提高MOUD的依从性，并促进CP与OUD治疗的整合。鉴于LLM整体表现受限，研究也强调有必要进一步开发能在OUD/CP场景下提供可操作性洞见的大语言模型。                                                                                                                                                                                  | False        | 这篇文章主要关注的是医疗健康场景：利用可穿戴设备与机器学习/LLM来预测慢性疼痛加重和阿片复发风险。研究重点在于：数据采集（可穿戴设备的生理/行为信号）、医疗临床相关变量分析，以及比较传统机器学习模型与LLM在该具体医疗预测任务中的效果。整体更偏向数字医疗、临床决策支持与健康监测应用。与您的研究方向：云原生、AI+运维（SRE）、多智能体系统、操作系统，并没有直接的系统架构、分布式系统、资源调度、AIOps、故障预测、多智能体协作机制或系统软件设计等内容。文中使用的AI方法看起来主要是通用机器学习建模和对LLM能力的简单探索，没有涉及云原生部署、可观测性管线、运维自动化或多智能体在医疗平台中的协调控制，也不属于您不喜欢的“纯算法”但同样不触及系统层面的问题。因此从您当前偏好的研究方向来看，这篇文章的系统与工程价值有限，可作为了解AI在医疗可穿戴应用的一个案例，但不值得投入太多精力深入阅读。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | https://arxiv.org/pdf/2511.19577 |
|    2511.2  | Fara-7B: An Efficient Agentic Model for Computer Use                                                                                     | Fara-7B：一种高效的计算机使用智能体模型                        | 当前的计算机使用智能体（Computer Use Agents, CUA）发展受限于缺乏大规模、高质量的人机交互轨迹数据集。与基于大量文本数据训练的通用大语言模型不同，CUA 领域尚没有类似规模的交互语料。为此，本文提出 FaraGen，一套面向多步网页任务的合成数据生成系统。FaraGen 能够从常用网站自动提出多样化任务、生成多次解题尝试，并通过多种验证机制筛选出成功轨迹，整体在吞吐量、成功率和任务多样性上表现良好，且每条通过验证的轨迹成本约为 1 美元。基于这些数据，作者训练了 Fara-7B，一个“原生”计算机使用智能体模型：它仅依赖网页截图感知界面，通过预测坐标执行操作，并且参数规模较小，能够在设备端运行。实验表明，Fara-7B 在 WebVoyager、Online-Mind2Web 以及作者新提出的 WebTailBench 等基准上，优于同规模的其它 CUA 模型，并在性能上接近更大规模的前沿模型，体现了可扩展的数据生成系统在推动小而高效的智能体模型方面的价值。作者计划在 Microsoft Foundry 和 HuggingFace 开放 Fara-7B 权重，并公开 WebTailBench 基准。                                                                                                  | True         | 这篇论文与“云原生、AI+运维（SRE）、多智能体系统、操作系统方向”有比较紧密的交集，值得深入阅读，原因如下：<br/><br/>1）与智能体、工具型 AI 强相关<br/>论文核心是构建一个“Computer Use Agent”，即能够真实操控浏览器/桌面环境的智能体，而不是纯文本对话模型。这非常贴合你在“多智能体系统、AI+运维（SRE）”中的潜在需求：<br/>- 在 SRE 场景中，很多工作是通过 Web 控制台、监控面板、云管理平台完成的，一个能看截图、点按钮、填表单的 CUA 模型，可以自然扩展为：自动化巡检、告警处置、配置变更、跨系统联动等“操作型 AI 运维助手”。<br/>- 论文强调小模型（7B）就能在设备端运行，这与“云原生+边缘/本地部署”的理念契合，便于在本地集群节点、堡垒机或运维终端中落地，而不必依赖超大模型或外部云 API。<br/><br/>2）对 AI+运维与自动化工作流的启发<br/>论文重点在于：<br/>- 大规模合成交互数据 FaraGen 的设计：如何定义任务、生成多种解法、利用多重验证器筛选成功轨迹。<br/>- 这套方法可以迁移到运维领域：你可以用运维系统（Grafana/Kibana/云控制台等）为场景，构造类似的合成任务（如“定位 CPU 异常实例并横向查看其日志”、“为某集群扩容并更新负载均衡配置”等），用脚本或规则做“成功验证器”，自动生成大量人机交互轨迹，为你的“运维 CUA 模型”提供训练数据。<br/>- 新 benchmark WebTailBench 的设计思路也值得借鉴，用来构建“运维场景智能体评测集”（例如涵盖常见 SRE runbook 的网页任务）。<br/><br/>3）与操作系统/系统软件方向的联系<br/>- 该模型本质上是“基于 GUI 截图+坐标动作”的 OS 级交互智能体，可视作一种“通用 GUI 自动化层”，从操作系统/系统软件角度看，是对传统脚本化自动化（shell、Ansible、Selenium）的一种智能化替代。<br/>- 如果你关注“AI 与操作系统的结合”（例如 AI-native OS、Agentic OS），这篇工作展示了如何让模型直接理解和操控图形界面，是重要的系统能力之一，对设计“AI 可直接驱动的系统接口和抽象”会有启发。<br/><br/>4）与云原生的间接关联<br/>论文本身并不专门讲云原生或 Kubernetes，但：<br/>- 其 CUA 能力可以直接用于操作云原生平台的 Web 控制台；<br/>- 小模型可 on-device 部署，可考虑与边缘节点、运维终端、或云原生 sidecar/service 形式相结合，实现“就近的智能控制层”。<br/><br/>5）不属于你明确不喜欢的方向<br/>- 虽然用到 CV（通过截图感知）和模型训练，但重点不是视觉识别、也不是纯 Transformer 新算法或推荐算法，而是“如何构建高效的计算机使用智能体与合成数据系统”。<br/>- 算法创新更多是系统层面和数据生成管线，而非你不喜欢的“纯算法推导型论文”。<br/><br/>综合来看，这篇文章在“多智能体系统、AI 驱动的 GUI/网页操作、可在本地运行的小模型智能体、面向复杂任务的合成数据系统”方面提供了系统性方案和公开模型/数据，非常适合作为你在 AI+运维、云原生场景下设计“可真实执行操作的智能体系统”的重要参考，因此建议认真阅读。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | https://arxiv.org/pdf/2511.19663 |
|    2511.2  | HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization                                         | HeaRT：一种用于模拟/混合信号电路设计优化的分层电路推理树智能体框架           | 传统的人工智能驱动的模拟/混合信号（AMS）电路设计自动化方法，往往依赖高质量数据集来刻画底层电路行为，可迁移性差，且缺乏自适应机制。本文提出 HeaRT，这是一种面向自动化设计闭环流程的基础推理引擎，也是朝向智能化、自适应、类人风格电路设计优化迈出的第一步。HeaRT 通过分层电路推理树结构来进行设计推理与决策，在作者构建的包含 40 个电路的基准库上，即便随着电路复杂度提高，仍然能保持超过 97% 的推理准确率以及超过 98% 的 Pass@1 表现，同时推理所需的 token 预算低于当前主流基线方法的 0.5 倍。实验结果表明，在电路尺寸（参数）优化和拓扑结构自适应设计任务中，HeaRT 在多种优化方法下都能实现超过 3 倍的收敛加速，并能在优化过程中保持原有设计意图。                                                                                                                                                                                                                                                                                 | False        | 这篇工作核心是在模拟/混合信号电路设计领域，构建一个面向 AMS 设计优化的“推理型智能体框架”，重点是：如何让智能体在电路拓扑与参数空间中更高效地搜索和优化，解决电路自动化设计中数据依赖强、可迁移性差的问题。虽然从形式上看，它强调了“推理引擎”“智能体框架”“自动化闭环”等概念，但其应用场景高度聚焦在电子设计自动化（EDA）和电路优化，属于相对垂直的工程设计智能化，而不是通用多智能体系统、云原生运维或操作系统方向。<br/><br/>结合你的研究关注点：<br/>1）云原生与 AI+运维（SRE）：文中没有涉及分布式系统、集群调度、服务自治、可观测性或智能运维；框架也不是部署在云原生环境内的 AIOps/自愈系统，而是用于芯片设计流程中的专用设计智能体，因此与云原生/SRE 的直接关联较弱。<br/>2）多智能体系统：从题目和摘要看，HeaRT 更像是一个单智能体或单推理引擎框架，未体现多智能体协同、任务分解与调度、角色分工等典型 MAS 议题，而是围绕“分层电路推理树”这一内部结构展开，偏单体智能体增强，不符合你关注的多智能体系统研究方向。<br/>3）操作系统方向：工作场景在 EDA 工具链和设计空间搜索，未涉及 OS 设计、资源管理、调度、内核机制或系统级智能控制，也没有系统架构对智能体和底层运行时的讨论，与 OS 研究的交集非常有限。<br/>4）算法/应用属性：尽管文章声称是一种“框架”和“推理引擎”，本质仍然是围绕 AMS 电路设计优化的专用智能体方法，偏向特定工程应用，与通用的云原生、系统级 AI 运维、智能代理平台搭建的关系不大。你明确表示不偏好纯算法和偏窄场景的应用，这篇文章更多是 EDA+AI 的交叉应用研究，可能不符合你的兴趣重心。<br/><br/>因此，从你的研究方向来看，该文的可迁移启发有限，除非你对“如何在高度结构化工程领域设计面向优化任务的专用智能体”这一点有特别兴趣，否则不太值得投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | https://arxiv.org/pdf/2511.19669 |
|    2511.2  | FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking                                                | FISCAL：面向高效事实核查的金融合成“声明-文档”增强学习框架              | 大型语言模型在金融场景中的应用既要求事实可靠性，又要兼顾计算效率，但现有系统往往存在幻觉问题，并依赖体量巨大的模型。本文提出了FISCAL（Financial Synthetic Claim-Document Augmented Learning），一个面向金融事实核查的模块化合成数据生成与学习框架。作者利用该框架构造了FISCAL-data数据集，并在此基础上训练了一个轻量级的金融数值声明校验模型MiniCheck-FISCAL。实验表明，相比基线模型，该模型在金融数值事实核查任务上有明显提升，性能超过GPT-3.5 Turbo以及同尺寸的多个开源模型，并接近Mixtral-8x22B、Command R+等大规模模型的准确率。在外部数据集FinDVer和Fin-Fact上的表现可与GPT-4o、Claude-3.5媲美，同时优于Gemini-1.5 Flash。结果表明，结合领域特定合成数据和高效微调，可以让小模型在金融AI的事实核查任务中达到接近SOTA的准确性、鲁棒性和可扩展性。论文还公开了数据集与训练脚本。                                                                                                                                                       | False        | 从你的研究兴趣来看，你重点关注云原生、AI+运维（SRE）、多智能体系统以及操作系统相关方向，并且不喜欢偏纯算法与特定应用（如推荐、CV、纯LLM算法细节）为主的研究。该论文主要聚焦于金融领域的事实核查任务，核心贡献在于：1）提出一个面向“金融数值声明-支撑文档”的合成数据生成框架；2）基于该数据训练一个轻量级金融声明校验模型，并在多个金融数据集上对比GPT-3.5、GPT-4o、Claude等模型，证明小模型在特定金融任务上的效果可以逼近或超越大模型。 <br/><br/>从方法和落地形态上看：<br/>- 工作本质上是一个垂直领域（金融）的任务建模与数据增强+精调流程，没有涉及云原生架构、部署框架、服务治理、弹性伸缩、观测性、可用性工程等SRE相关内容；<br/>- 没有讨论在生产系统中如何进行模型治理、监控、自动回滚、灰度发布等与AI运维相关的工程问题；<br/>- 没有涉及多智能体协同、任务分解、Agent框架或操作系统层面的资源管理与调度问题；<br/>- 虽然强调“轻量级模型”和“计算效率”，但更多是模型尺寸与推理性能层面的对比，而非系统层面的性能工程或云原生下的成本优化策略。 <br/><br/>因此，这篇文章在技术路线和应用领域上都偏向“金融领域的事实核查模型与数据合成方法”，与云原生、SRE运维、多智能体系统或操作系统的结合度很低。如果你目前不打算专门深入“金融+LLM事实核查”的垂直应用，这篇论文对你的研究方向直接参考价值有限，可以不必优先阅读。若未来你考虑做“领域小模型+合成数据”在运维日志分析或SRE预警中的迁移研究，可以再回过头把它当作一个合成数据+小模型精调的应用案例参考。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | https://arxiv.org/pdf/2511.19671 |
|    2511.2  | Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions                                           | 利用大语言模型扩展试题与教育标准对齐的规模：准确性、局限性与解决方案             | 随着教育系统的发展，确保评测题目与课程内容标准保持一致，对于公平性和教学相关性至关重要。传统的人工作题与标准对齐审查虽然准确，但在大规模题库场景下往往缓慢且耗费大量人力。本文研究大语言模型（LLM）能否在不牺牲准确性的前提下，加速这一对齐流程。作者基于 K-5 年级超过 12,000 个“题目-技能”配对，选取 GPT-3.5 Turbo、GPT-4o-mini、GPT-4o 三个模型，在三类贴近真实业务的问题上进行测试：（1）识别题目是否与给定标准错配；（2）在完整标准集合中为题目选出正确技能；（3）通过预筛选候选技能列表来辅助分类。研究一中，GPT-4o-mini 在识别对齐状态（包括较细微的错配）时的准确率约为 83%–94%。研究二发现，模型在数学类标准上的表现保持较好，但在语文阅读类标准上表现较弱，主要由于标准之间语义重叠度更高。研究三表明，对候选技能进行预过滤能显著提升结果质量，在此策略下，正确技能有超过 95% 的概率出现在前五个候选建议中。整体结果显示，在结合候选过滤策略的前提下，LLM 可以在保持对齐准确度的同时大幅降低人工审查负担。作者建议构建“LLM 预筛+人工复核”的混合流水线，用于持续的题目校验和教学标准对齐，以实现可扩展的教育评测内容管理。                                                                          | False        | 这篇文章主要聚焦在教育测评领域中“试题与教育标准对齐”的具体应用场景，核心贡献是用 GPT 系列大模型做题目-技能标签对齐的效果评估与流程设计。尽管涉及大语言模型和“混合流水线”（模型预筛 + 人工复核）的思路，但整个工作高度面向教育行业的标注与内容校验，不涉及云原生架构、运维/可观测性、SRE 自动化流程、多智能体系统协作、或操作系统机制等你关心的基础设施与系统层问题。论文更像是一个垂直领域应用案例研究：如何用现成 LLM 对大规模教育题库进行标签对齐提效，探讨的是模型在不同学科语义空间中的表现差异，以及通过候选过滤提升召回率和准确率，并给出对教育工作流的业务建议。从你的研究方向来看，这篇文章缺少系统工程、云原生部署、自治运维、智能体编排、调度策略或资源管理等内容，也没有方法层面对 AI+运维或多智能体系统有可迁移的技术创新。因此，除非你个人对教育测评应用非常感兴趣，否则在研究价值上与当前方向关联较弱，不推荐投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | https://arxiv.org/pdf/2511.19749 |
|    2511.2  | Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs                                                             | 面向工具集成推理的视觉语言模型代理型强化学习扩展方法                     | 近年来的视觉语言模型在图像理解上表现出色，但在“带着图像思考”，尤其是通过多步视觉交互进行推理方面仍有限。本文提出 VISTA-Gym，这是一个可扩展的训练环境，用于激励视觉语言模型在与工具集成的场景下进行视觉推理与代理型强化学习。VISTA-Gym 将来自 13 个数据集的 7 类真实多模态推理任务进行统一封装，提供标准化的视觉工具接口（如目标定位、解析等）、可执行的交互回路、可验证的反馈信号以及高效的轨迹记录机制，从而支持大规模的“视觉智能体”强化学习训练。作者基于 VISTA-Gym 训练了 VISTA-R1，使模型能够通过多轮交互轨迹采样和端到端强化学习，将工具调用与代理式推理交织起来。实验表明，在 11 个强调推理能力的 VQA 公共基准上，VISTA-R1-8B 相比同规模最新模型取得约 9.51%-18.72% 的性能提升，证明 VISTA-Gym 是解锁视觉语言模型工具集成推理能力的有效训练平台。                                                                                                                                                                                                            | False        | 这篇工作核心集中在：面向视觉语言模型的代理型强化学习训练环境（VISTA-Gym），以及在该环境上训练能调用视觉工具的 VLM（VISTA-R1）。其主要贡献点是：1）构建多模态视觉推理环境；2）统一视觉工具接口（grounding、parsing 等）；3）端到端强化学习训练一个多轮交互的视觉智能体，以提升 VQA 类任务表现。整体而言，它是一个“VLM+工具+强化学习”的框架，主战场是视觉推理和多模态问答。 <br/><br/>从你的研究兴趣来看：<br/>- 云原生：文中没有涉及分布式系统、容器、K8s、服务编排、可观测性等云原生基础设施内容，也没有从系统/平台角度讨论如何在云环境中扩展或部署此类训练环境。<br/>- AI+运维(SRE)：论文没有围绕系统可靠性、告警、自动化运维、智能排障、日志/指标分析等 SRE 场景展开，而是以通用多模态推理和视觉问答基准为目标任务。<br/>- 多智能体系统：尽管使用了“agentic”“agent”的说法，但这里的“智能体”更多是指一个具备工具调用能力的单一 VLM 智能体，通过 RL 学习交互策略，论文不关注多智能体协作、博弈、任务分解等 MAS 典型议题。<br/>- 操作系统方向：没有涉及 OS 结构、调度、资源管理、隔离、安全等问题。其“环境”是机器学习训练环境，而不是操作系统层面的平台或内核机制。<br/><br/>该论文的技术重心仍然是：<br/>- 针对视觉语言模型的工具调用策略学习；<br/>- 强化学习训练框架与基准；<br/>- 提升 VQA 任务表现。<br/><br/>由于你明确表示不偏好纯算法/模型改进（特别是与视觉相关的工作），而本篇主要贡献正是针对 VLM 的推理能力和视觉强化学习框架，因此与“云原生、AI+运维、多智能体系统（系统级）、操作系统”这些方向的直接相关度非常有限。目前从摘要和元信息来看，它不提供和系统架构、运维自动化、云平台设计等密切相关的可迁移方法或经验。除非你后续正好需要参考“如何为工具增强型模型构建 RL 训练环境”这一点做概念借鉴，否则不建议投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | https://arxiv.org/pdf/2511.19773 |
|    2511.2  | NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents                                   | NOEM³A：一种面向移动智能体的神经符号本体增强多意图理解方法               | 本文提出了一种用于移动AI智能体多意图理解的神经符号框架 NOEM³A，通过将结构化意图本体与小型语言模型相结合，实现对多意图对话的高效理解。方法采用检索增强提示（RAG）、logit 偏置以及可选的分类头，将符号化的意图结构同时注入输入与输出表示中。作者提出了一种新的评价指标——语义意图相似度（Semantic Intent Similarity, SIS），基于层次化本体深度来度量意图间的语义接近程度，即便预测意图在词面上不同也能体现语义相似性。实验在 MultiWOZ 2.3 中具有歧义或高难度的对话子集上进行（标注由 GPT-o3 生成），结果表明：结合本体增强的 3B 规模 LLaMA 模型，其多意图理解准确率接近 GPT-4（85% 对 90%），却只需极小的能耗与内存开销。定性分析显示，本体增强模型能产生更扎实、去歧义的多意图解释。研究结果表明，通过符号对齐可以有效提升设备端自然语言理解（on-device NLU）的准确性与效率。                                                                                                                                                                                           | True         | 这篇工作虽然是自然语言理解与对话意图识别方向，但有几个与您的研究方向高度相关的点：1）移动智能体与设备端部署：作者明确面向“mobile AI agents”和“on-device NLU”，强调在受限算力、内存与能耗下，用小模型（3B）接近 GPT-4 效果，这与云原生+边缘/端侧AI部署、AI基础设施的资源效率优化密切相关，可为您在云-边-端协同体系设计中提供参考思路，尤其是如何通过结构化知识与推理减少对大模型推理资源的依赖。2）神经符号与多智能体场景：文中强调引入本体和符号对齐，增强多意图理解的“可解释性”和“结构化对齐”。在多智能体系统和AI+运维场景下，如果有多个代理或Agent协同完成运维任务（如自动化故障排查、变更理解），引入类似的本体和意图结构，可以用于：   - 定义运维任务/告警/服务的层次化本体，帮助Agent正确理解复杂多意图指令或告警组合；   - 通过符号化结构降低对话式运维Agent之间的歧义，提升协调与决策一致性。3）与 AI+运维（SRE）的潜在结合：虽然论文数据集是通用对话（MultiWOZ），但方法本质是“在领域本体约束下的意图识别框架”。在SRE场景中，您可以替换为运维领域本体（服务拓扑、告警类型、操作动作、故障模式等），在：   - 智能告警聚合与分类（多告警多意图理解）；   - 运维知识库检索前的意图判定；   - 多智能体协同处理复杂变更/工单流程中的指令理解；中复用其核心思路。相比于纯算法/纯推荐/纯Transformer新结构，该工作更偏方法论与系统层面：如何用本体和RAG结合小模型来达到高效、多意图理解，这与您在系统架构、云原生AI基础设施和多Agent协同设计中的关注点是契合的。而且其强调能耗与内存占用，为在云原生环境中做弹性伸缩、资源调度时提供有价值的真实实验数据和设计参考。综合来看，这篇论文不属于您不喜欢的“纯算法”或“CV/推荐/新Transformer结构”类型，更偏系统化的AI方法与知识结构注入，对设计面向运维/多智能体的对话代理与端侧Agent有直接启发，因此建议继续阅读，重点关注其：本体构建与集成方式、RAG与logit bias在推理流程中的工程化设计，以及他们如何在小模型上达到接近GPT-4的效果，这些都可迁移到云原生AI系统与SRE智能体设计中。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | https://arxiv.org/pdf/2511.19780 |
|    2511.2  | KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)                                  | KOM：用于膝骨关节炎精细化管理的多智能体人工智能系统                    | 膝骨关节炎（KOA）在全球影响超过6亿人，伴随显著的疼痛、功能受限和残疾。个体化的多学科干预有潜力减缓疾病进展并提升生活质量，但通常需要大量医疗资源和专业知识，在资源有限的场景中难以实施。为解决这一问题，作者提出了KOM，一个多智能体人工智能系统，用于自动化完成KOA的评估、风险预测和治疗方案制定。该系统通过多个协同智能体，辅助临床医生在KOA诊疗路径上的关键任务，并根据患者个体特征、疾病状态、风险因子和禁忌证生成定制化管理方案。在基准实验中，KOM在影像分析和处方生成方面的表现优于若干通用大语言模型。在一项随机三臂仿真实验中，KOM与临床医生协同工作可将总诊断与方案制定时间减少约38.5%，且治疗质量优于单独由医生或单独由系统完成的情形。结果表明，KOM有望推动KOA管理自动化，并在嵌入真实临床流程后提升医疗效率。作者强调，KOM的模块化多智能体体系结构可能为其他慢性病的AI辅助管理系统设计提供参考。                                                                                                                                                                                                                 | True         | 这篇论文与您的研究方向有较高相关度，主要体现在以下几点：<br/>1）多智能体系统：KOM本质上是一个面向真实复杂业务流程（KOA诊疗路径）的多智能体系统。论文强调模块化架构和不同智能体在评估、风险预测、处方生成等环节的分工与协作，对多智能体如何围绕一个复杂任务进行职责切分、流水线编排和决策协同，提供了一个完整的、面向生产级应用的案例。这与您关注的多智能体系统非常贴近，且不仅停留在算法层，而是涉及系统工程和流程设计。<br/>2）AI+运维/自动化工作流的类比价值：虽然场景是医疗，但本质是“用AI多智能体自动化一个涉及多角色、多步骤的专业工作流”。KOM和医生协同以缩短决策时间、提高质量，这与SRE/运维中“AI助理+人类工程师”协同处理复杂事件、变更评审、容量和风险评估在模式上高度相似。您可以借鉴其：<br/>- 如何将完整业务流程拆分为多个可自动化子任务（评估、预测、决策建议）；<br/>- 如何定义每个智能体的输入输出接口、上下文信息和约束；<br/>- 如何在系统内形成“AI建议 — 人类审查 — AI再协助”的闭环，以保证安全性与效率平衡。<br/>3）体系结构和工程实践潜在启发：摘要提到KOM具备模块化架构，且在影像分析与处方生成之间做了清晰划分，这种“多模态、多任务、多代理”的架构，对云原生和AI系统工程有一定启发：<br/>- 可以类比为不同微服务/agent围绕统一病例上下文协同工作；<br/>- 涉及如何管理不同模型组件（如影像分析模型、LLM决策组件）之间的协同与调度；<br/>- 为未来在云原生环境中部署多智能体医疗系统提供了需求视角（如可扩展性、可组合性、可替换性）。虽然论文不一定深入云原生实现细节，但从系统角度对您思考“AI多智能体系统如何在复杂领域落地与演进”有参考价值。<br/>4）与您不偏好的领域关系：这篇工作重点不在提出新的底层算法或Transformer架构，而在于如何利用现有模型构建一个面向真实场景的多智能体系统和工作流，属于应用型系统研究，而非纯算法或推荐算法、CV新模型研究。影像分析部分更像是系统中的一个组件，而非论文的算法核心，因此不会过度偏向您不喜欢的纯视觉/算法方向。<br/>综合判断：如果您当前关注的是如何设计、编排和落地多智能体AI系统，并把AI嵌入到复杂业务流程、提升人机协同效率，那么这篇论文值得继续细读。尤其是它在医疗场景中的系统拆解、agent设计和评估方式，均可迁移类比到运维、SRE或其他复杂操作系统/平台管理场景中。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | https://arxiv.org/pdf/2511.19798 |
|    2511.2  | A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization                                                        | 面向查询自适应提示优化的统一评估指导框架                           | 现有大多数提示（prompt）优化方法通常只针对单一静态模板进行改写，在复杂且动态的用户场景下效果有限。已有的面向查询的提示优化方法往往依赖不稳定的文本反馈或黑盒奖励模型，提供的优化信号既薄弱又难以解释。更根本的问题在于，提示质量本身缺乏统一而系统的定义，导致评估信号零散且不可靠。本文首先提出一个以性能为导向、系统且全面的提示评估框架。基于该框架，作者进一步训练了一个“无执行”（execution-free）的评估器，只需输入文本即可预测多维度的提示质量得分。该评估器再作为指导信号，驱动一个“度量感知”的优化器，对提示的失败模式进行诊断，并以可解释、面向具体查询的方式重写提示。实验表明，该评估器在预测提示性能方面达到了最优精度，而由其指导的优化过程在八个数据集和三种基础模型上，均显著优于静态模板和现有的查询依赖方法。总体而言，论文提出了一种统一、度量驱动的提示质量视角，并展示了基于评估信号指导的优化流水线可以在多种任务上、跨模型地提供稳定、可解释的性能提升。                                                                                                                                                                                     | True         | 这篇工作聚焦于大模型提示工程中的“评估与优化一体化”问题，虽然属于提示优化方法论，但与传统你不喜欢的纯算法（如推荐算法、Transformer结构改进、CV识别）有本质区别，更偏向于工程与系统层面的“如何可靠地管理和优化提示”，在AI+运维、多智能体系统以及云原生AI服务治理场景中有较强的关联。<br/><br/>1）和你的研究方向的关系：<br/>- 云原生 / AI 服务治理：在Kubernetes、Serverless 等云原生环境中部署 LLM 服务时，需要对不同租户、不同业务查询动态生成/优化 prompts，以满足SLA、降低错误率。这篇论文提供了一个“统一的、度量驱动的提示质量评估器 + 指导式优化器”的架构思路，可直接映射到：在生产环境中，将 evaluator 作为一个可组合的微服务，对各业务侧的 prompts 进行自动打分和优化，再由调度/策略引擎根据分数做路由、回滚或策略调整。<br/>- AI+运维（SRE）：越来越多团队在做 LLM 助理用于运维排障、日志分析、Runbook 生成等。实际工程问题之一就是：给 LLM 的 prompt 在不同告警、不同系统上下文下往往需要动态调整，而且很难“稳定可控”。论文提出的“执行无关评估器 + 查询相关重写”机制，可以用于：<br/>  - 为运维助手的 prompts 建立统一质量指标（如准确性、可执行性、可靠性、可解释性）。<br/>  - 将 evaluator 放入运维流水线，对低质量 prompt 场景提供自动重写建议或直接替换，从而减少人工调参。<br/>  - 将其作为 SRE 平台中一类“LLM质量控制组件”，为不同业务线自动生成更鲁棒的运维对话模版。<br/>- 多智能体系统：多智能体框架中，每个 agent 的行为在很大程度上是由系统 prompt 和工具调用说明驱动的。此类系统复杂、交互动态，和论文中“复杂、动态用户场景下的查询依赖优化”非常类似。这篇论文提供：<br/>  - 一种统一标准来评估 agent prompt 的“质量”（多维指标），有助于自动化调参和 agent 角色配置。<br/>  - 一个可集成的优化器，可以在运行数据或仿真数据上迭代优化各 agent 的提示，使多智能体系统更稳定、性能更好。<br/>- 操作系统 / AI增强系统：如果你关注“AI嵌入到OS或平台层”的方向，比如把 LLM 作为系统调用接口、任务调度辅助或权限决策辅助，那么对不同系统调用/任务生成专门 prompt 并持续优化是一个核心系统问题。论文中“统一度量 + 无执行评估 + 解释性重写”的整体框架，是构建“系统级 LLM 提示管理子系统”的一个强参考架构。<br/><br/>2）不太偏你不喜欢的方向：<br/>- 文章没有在Transformer结构、注意力机制等底层模型算法上做复杂创新，也不是推荐系统或纯CV领域工作。<br/>- 核心贡献在于：<br/>  - 提出一个系统化的提示质量定义与评价框架。<br/>  - 训练一个执行无关的质量评估器，将其作为“可解释反馈信号”。<br/>  - 利用该评估器指导提示的查询相关重写与优化，并在多任务、多模型上验证稳定性。<br/>- 这更像是“上层控制与质量治理”的工作，而不是底层模型算法，和工程系统实践相对贴近。<br/><br/>3）适合你关注的角度：<br/>- 作为参考架构：可以思考如何将他们的 evaluator 以微服务或Sidecar的形式嵌入云原生LLM平台，作为统一质量评估组件，对多模型、多租户请求的 prompts 做打分与审计。<br/>- 和Ops/SRE平台结合：你可以借鉴其“多维指标 + 失败模式诊断”方式，为运维类LLM对话定义专门的指标（例如：命令安全性、操作可行性、信息完整性），形成你的AI运维平台中的质量基线。<br/>- 和多智能体调参结合：将论文的“查询依赖重写”思想用于多agent系统中自动演化各agent的角色提示与工具使用说明。<br/><br/>综合来看，这篇论文为“如何系统地评估和优化LLM提示”提供了较完整的框架，与云原生AI服务治理、AI+运维、以及多智能体系统中的提示管理问题高度相关，不是单纯的底层算法工作，值得你精读尤其是其架构设计与评估指标部分。                                                                                                                                                                                         | https://arxiv.org/pdf/2511.19829 |
|    2511.2  | Reinforcement Learning with $ω$-Regular Objectives and Constraints                                                                       | 具备 ω-正则目标与约束的强化学习方法                            | 传统强化学习通常依赖标量奖励来描述任务目标，这种方式难以表达复杂的时间逻辑、条件性目标以及安全关键需求，并容易导致“奖励规避/投机”现象。ω-正则目标是一类可表达丰富时序逻辑性质的框架，可以精确描述行为约束与长期性质。然而现有工作多将性能度量归结为单一标量（如期望回报或满足目标的概率），在存在可容忍风险水平的场景中，这种单指标方式会掩盖安全与性能之间的权衡。本文将ω-正则目标与显式约束结合起来，使安全要求与优化目标分离建模：通过将任务目标和安全约束都表示成ω-正则形式，并为约束设定可接受阈值，提出一种基于线性规划的模型化强化学习算法。在模型已知或学习到之后，该算法在极限情况下可以找到同时满足：最大化满足ω-正则目标概率、并在给定阈值内满足ω-正则约束的策略。作者进一步建立了到受限极限平均（constrained limit-average）问题的可译性，并证明该翻译在最优性上是保持的，为复杂时序安全约束下的强化学习策略合成提供了理论基础。                                                                                                                                                                                               | False        | 这篇文章主要聚焦于强化学习理论中如何用ω-正则目标和约束来刻画复杂时序逻辑、安全约束和性能权衡，并提出基于线性规划的模型化RL算法。从元信息和摘要来看，工作重点是：<br/>- 强化学习目标由普通标量奖励拓展为ω-正则时序逻辑规范；<br/>- 将安全和性能分别建模为ω-正则目标和约束；<br/>- 提出一个在马尔可夫决策过程模型上的线性规划求解框架；<br/>- 提供到受限极限平均问题的理论转化与最优性证明。<br/><br/>与你的研究方向对比：<br/>- 云原生、AI+运维(SRE)：本文没有讨论分布式系统、服务编排、云原生基础设施或实际运维场景，更偏向抽象MDP和策略合成，不涉及Kubernetes、服务可靠性工程等工程问题。<br/>- 多智能体系统：文中没有体现多智能体交互或协作博弈，更像是单智能体在带复杂规范的环境中的决策问题。<br/>- 操作系统方向：没有涉及OS调度、资源管理、内核机制等，主要是形式化规范下的决策与优化，与操作系统实现和系统软件工程关联度较弱。<br/>- 人工智能总体方向上，这确实是AI理论里一个重要分支（安全与约束强化学习、形式化规范下的决策），但更偏向算法理论和形式方法，而不是系统或工程层面的AI+运维。<br/><br/>你明确表示不喜欢纯算法类研究，而这篇文章本质上是：<br/>- 在形式化规范（ω-正则、时序逻辑）下的强化学习建模；<br/>- 基于线性规划与限平均MDP的理论算法设计和收敛/最优性分析；<br/>- 仅从理论上讨论安全-性能权衡，没有看到与生产级云原生基础设施、SRE实践、多智能体编排或OS资源管理的具体结合。<br/><br/>如果你的当前工作更偏向：<br/>- 在云原生环境中如何部署、观测和治理AI系统，<br/>- AI用于自动化运维、告警处理、容量规划、SLO自适应管理，<br/>- 多智能体协作在复杂系统中的任务分解与执行，<br/>- 操作系统/基础设施层面的智能调度与自治，<br/>那么这篇文章与这些方向的直接工程联系较弱，主要价值是提供一种更加形式化和安全约束感知的RL框架，可作为未来如果你想把“形式化规范 + RL”引入SRE/系统控制时的理论参考。但在没有明确打算做这条理论线的前提下，它并不高匹配你的兴趣与偏好。<br/><br/>因此，综合你的研究兴趣与你不喜欢纯算法型论文的偏好，我认为这篇论文不太值得你投入时间做深入阅读全文，最多可简单浏览结论和方法框架，以了解“约束与安全时序规范强化学习”的思路即可。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://arxiv.org/pdf/2511.19849 |
|    2511.2  | MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support         | MicroSims：一种面向AI生成、可扩展教育仿真的通用嵌入与自适应学习支持框架      | 教育仿真长期被认为是提升学习效果的有力工具，但其开发往往需要大量资源和技术能力。本文提出 MicroSims 框架，用于创建轻量级、交互式教育仿真，可借助人工智能快速生成，在各类数字学习平台上通过 iframe 实现通用嵌入，并可在无编程背景的情况下轻松定制。MicroSims 结合了三方面创新：(1) 标准化设计模式，支持 AI 辅助生成仿真内容；(2) 基于 iframe 的架构，实现跨平台嵌入与沙箱式安全隔离；(3) 透明、可修改的代码结构，支持二次定制和教学可解释性。作者给出了包含设计原则、技术架构、元数据标准和开发工作流的完整框架。基于物理教育和 STEM 领域的实证研究与元分析，论文指出交互式仿真相较传统教学可将概念理解提升约 30–40%。MicroSims 在保留这些优势的同时，解决了成本高、技术门槛高和平台依赖等问题，为低成本智能交互教材和教育公平提供技术基础，并讨论了基于 MicroSims 构建 AI 驱动自适应学习系统的实现要点与未来方向。                                                                                                                                                                                  | False        | 从摘要来看，这篇文章主要聚焦在教育技术方向：利用 AI 快速生成交互式教学仿真内容，并通过 iframe 等方式在各类数字学习平台中通用嵌入，同时强调教学法、标准化设计模式以及教育公平。虽然它提到 AI 辅助生成和未来的自适应学习系统，但核心贡献并不在云原生基础设施、运维自动化（SRE）、多智能体系统、操作系统或 AI+运维等方面，而更偏向于教学内容生成框架与教学仿真产品化方案。<br/><br/>与您的研究兴趣对比：<br/>- 云原生 / SRE：文中未体现容器编排、弹性伸缩、可观测性、自动化运维、服务治理等云原生或运维工程相关内容。iframe 的“通用嵌入”和“沙箱安全”更偏前端和教育平台集成，而非系统级架构设计。<br/>- AI+运维：没有涉及利用 AI 做系统监控、故障诊断、容量规划、资源调度等内容。<br/>- 多智能体系统：没有提到 agent 协作、任务分解、自治决策或 MAS 框架，主要是 AI 辅助生成和交互脚本层面的设计模式。<br/>- 操作系统方向：无调度、内存管理、安全内核、多租户隔离等底层系统设计内容，安全隔离停留在网页沙箱层面。<br/><br/>除非你正好在做“智能交互教材”“AI 生成教育仿真内容”或教育平台的应用型项目，这篇文章对你的主线研究价值有限，更像是一个教育产品与教学设计层面的框架介绍，而不是系统或云原生/运维/多智能体技术上的突破。因此整体判断不建议投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | https://arxiv.org/pdf/2511.19864 |
|    2511.2  | Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G                                                                 | 面向6G的代理式人工智能赋能会话式具身智能网络                        | 在即将到来的6G时代，多具身智能设备（MEIDs）之间的语义协同对复杂任务的执行至关重要。但现有系统在多模态信息融合、自适应通信以及决策可解释性方面仍存在挑战。为此，本文提出了一种协同会话式具身智能网络（CC-EIN），集成多模态特征融合、自适应语义通信、任务协同以及可解释性机制。框架中，PerceptiNet模块对图像和雷达数据进行跨模态融合，生成统一的语义表示；自适应语义通信策略可根据任务紧急程度和信道质量动态调整编码方式与发射功率；语义驱动的协作机制支持在异构设备之间进行任务分解和无冲突协同；InDec模块通过Grad-CAM可视化增强决策过程的透明度。仿真结果基于震后救援场景，表明CC-EIN在保持较高语义一致性和能效的同时，实现了95.4%的任务完成率和95%的传输效率。                                                                                                                                                                                                                                                                               | True         | 这篇文章的核心并不是纯算法或单一模型结构，而是面向6G场景下的多智能体具身系统协同框架，重点在于：1）多智能体系统与语义协同：文章研究多具身智能设备（机器人、传感终端等）的协同感知、任务分解和冲突消解，属于多智能体系统和分布式智能控制的范畴，与多 Agent 协作和调度密切相关；2）通信与语义感知一体化：提出“自适应语义通信策略”，根据任务紧急度与信道质量动态调整编码与发射功率，本质上涉及边端协同、智能网络协议，这与云原生/边云协同体系在智能运维中需要的自适应通信策略有一定理念上的相通之处；3）具身智能与解释性：通过会话式的具身智能网络和可解释模块（InDec+Grad-CAM），强调可解释决策，对运维与SRE中需要的可观测性、可解释自动化决策具有参考价值；4）面向任务场景的系统设计：以震后救援为例，设计端到端的系统性框架，包括感知、多模态融合、协作决策和通信优化，而不是单纯提出一个新模型结构或推荐算法。这与您关注的“AI + 运维、多智能体系统、系统与架构层面”的思路更接近。虽然文章并未直接讨论云原生架构、k8s、SRE 工具链等，但它提供了一个完整的多设备、弱网络环境下的智能协同体系蓝图：如何在多智能体、多模态、多网络约束下设计可解释的智能系统。这对您在云原生环境中构建多 Agent/多服务协同、以及在资源受限和网络波动场景下做智能调度与运维决策时，有一定启发作用。总体来看，这篇文章偏系统与架构层面的多智能体具身智能与语义通信，而不是您不喜欢的纯算法/纯模型改进，因此建议进一步阅读全文，重点关注其系统架构设计、协作机制与自适应通信策略的抽象思路，可在AI+运维和多智能体调度框架设计上借鉴。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | https://arxiv.org/pdf/2511.19865 |
|    2511.2  | Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy                                          | 大型语言模型中的模拟自我评估：一种基于心理测量的AI自我效能研究               | 自我评估能力是构建可靠智能体系的重要方面，但当前对大型语言模型（LLM）的评估主要集中在任务准确率。本文借用人类心理测量领域的10项一般自我效能量表（GSES），设计用于提示并采集10个不同LLM在四种条件下的“自我效能”模拟自我评估：无具体任务、计算推理任务、社会推理任务以及文本摘要任务。实验表明：在不同随机题目顺序和多次重复施测下，LLM给出的GSES回答具有高度稳定性；不同任务条件下的自我效能评分显著不同，且整体得分低于人类常模。在计算和社会推理题目上，各模型几乎达到满分准确率，而在摘要任务上的表现差异较大。然而，自我评估得分与实际能力并不一致：一些自评较低的模型表现出很高的任务准确度，而部分自评较高的模型却生成质量较差的摘要。通过进一步的置信度追问，模型会做出小幅、主要是向下的修正，显示其初次评估中存在轻微高估倾向。质性分析发现，高自我效能评分往往伴随更自信、更拟人化的解释风格，而低评分对应更谨慎、去拟人化的表述。文章提出的“心理测量式提示”方法为分析LLM的沟通与自我描述行为提供了结构化视角，但并不能提供与实际性能良好校准的指标。                                                                                                                                           | False        | 从你的研究兴趣来看，你关注云原生、AI+运维（SRE）、多智能体系统和操作系统方向，更偏向工程体系、系统设计、智能体协作与自治运维等问题，而不喜欢偏纯算法或与推荐、视觉相关的工作。 本文核心是把人类心理学中的自我效能量表（GSES）移植到大型语言模型上，用心理测量学的方式研究LLM如何“自我评估”和表达自信程度。本质上是一项模型行为与心理量表结合的评测与分析工作，关注点在： 1）LLM在回答类似心理问卷时的一致性与稳定性； 2）自我报告的“自我效能感”与实际任务表现之间的相关性； 3）语言风格（拟人化、是否自信）与自评分数的关系。 这类研究与云原生、运维自动化、多智能体调度或操作系统机制没有直接联系，也没有涉及面向工程实践的自监控、自愈或系统级SRE场景；更多是从心理测量与模型行为解释出发，为理解LLM“自我描述”和置信度表达提供认知层面的洞察。如果你的当前工作不是在做： 1）提示工程中的“自信表达策略”设计， 2）AI安全或AI心理表征（如避免拟人化风险）， 3）针对大模型的心理测量学式评估框架， 那么这篇文章对你在云原生、AIOps、多智能体系统设计或OS层面的直接启发有限。它不涉及新的系统架构、调度机制、运维自动化流程、智能体协作协议，也不是多智能体自评估或自治控制的系统研究。因此，除非你在做“LLM自信度与语言风格”相关的元评估或人机交互研究，否则不建议投入太多时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | https://arxiv.org/pdf/2511.19872 |
|    2511.2  | RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation                                   | RPM-MCTS：基于蒙特卡洛树搜索的知识检索式过程奖励模型用于代码生成           | 基于树搜索的方法在提升大语言模型代码生成能力方面取得了显著进展，但由于难以有效评估中间算法步骤，以及无法及时定位和纠正错误步骤，这类方法往往会生成不正确代码并带来较大的计算开销。为解决这些问题，本文提出 RPM-MCTS 方法：将“知识检索”作为过程奖励模型并与蒙特卡洛树搜索结合，用于评估代码生成过程中的中间算法步骤。具体来说，该方法通过从知识库中检索相关信息来评估当前推理/算法步骤，从而避免对过程奖励模型进行复杂训练；在树扩展阶段利用相似度过滤去除冗余节点，保证推理路径的多样性；同时结合沙箱执行反馈，在生成过程中定位错误的算法步骤，实现及时且有针对性的修正。实验证明，在四个公开代码生成基准上，RPM-MCTS 相比当前最新方法取得更优性能，并在 token 消耗上约减少 15%；此外，利用 RPM-MCTS 构造的数据对基础模型进行全量微调，还能显著提升模型的代码能力。                                                                                                                                                                                                                                 | True         | 这篇工作不属于纯算法或视觉方向，而是结合大模型推理过程、知识检索、强化/搜索式决策（MCTS），应用于代码生成任务，本质上是对“如何让模型一步步推理并在过程中进行纠错和效率优化”的工程化方法探索。与您的研究方向的关联：1）AI+运维（SRE）与多智能体/自动化运维：代码生成在自动生成运维脚本、基础设施即代码（IaC）、Kubernetes/YAML 配置、CI/CD 流水线脚本、SRE 自动化修复 Playbook 等方面都很关键。这篇工作关注在生成过程中通过检索知识库和运行时沙箱反馈来动态纠错和减少计算消耗，与实际运维场景中“基于已有知识库（Runbook、告警手册）+ 真实执行反馈进行迭代修正”的模式非常类似，如果你在做自动化运维代理、多智能体协同修复、或智能脚本生成系统，这种过程奖励+搜索范式具有较高参考价值。2）云原生与知识库/代码库驱动的智能代理：云原生系统通常有庞大的配置与服务知识（API、微服务接口、配置规范），利用知识库检索约束代码或操作生成是典型需求。RPM-MCTS 用检索替代复杂过程奖励模型训练的思路，可以借鉴到“云原生智能运维助手”里：例如从内部文档、API 规范、历史变更记录中检索信息，对 LLM 产生的操作/脚本进行逐步评估和筛选。3）多智能体系统与搜索类控制：MCTS 加上“过程奖励”可以作为多智能体系统中规划、协作决策的一个重要范式。虽然本文场景是单个代码生成代理，但其框架（树搜索 + 知识检索评估 + 执行反馈修正）可以扩展到多智能体：例如多个代理提出不同修复方案，搜索并评估中间步骤，用执行结果与知识检索来给奖励。这对你做多智能体运维/自治系统时的“决策搜索和评估机制”有借鉴意义。4）操作系统/系统软件方向：文章侧重的是“利用沙箱执行反馈逐步修正生成过程”，这一点与系统级自动测试、沙箱化执行、安全执行环境密切相关。如果你的 OS 方向包含“安全沙箱、执行监测、自动测试与修复”等系统机制，那么将这类搜索+LLM+沙箱机制整合在系统层面是一个潜在研究方向。非推荐的点：这篇文章还是偏向代码生成任务的性能提升，不会深入到云原生架构或运维场景本身的工程细节，也不涉及系统实现层的内核机制。如果你当前工作更偏纯 OS 内核、调度、文件系统等传统方向，直接应用价值有限。但由于你关注 AI+运维和多智能体系统，我认为其“通过检索和执行反馈对生成过程进行结构化搜索和优化”的思路对你是有启发性的，因此整体上值得继续深入阅读，重点关注其过程奖励设计、知识检索与 MCTS 的集成方式，以及沙箱反馈融入搜索的一般方法。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | https://arxiv.org/pdf/2511.19895 |
|    2511.2  | Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity                                            | Semantic-KG：利用知识图谱构建用于度量语义相似度的基准数据集            | 大语言模型在开放式文本生成任务中的评估通常需要度量模型回答与人工参考答案之间的语义相似度。然而已有的语义相似度方法往往更偏向句法或词汇层面的相似，而未能真正抓住语义内容。同时，现有语义等价类基准数据集存在生成成本高（依赖主观人工标注）、在特定领域（如生物医学、金融等）可用性有限，以及“语义等价”定义含糊等问题。本文提出了一种新的方法：利用知识图谱自动生成用于评估语义相似度方法的基准数据集。具体做法是从知识图谱中构造一对对自然语言陈述句，这些句子对在语义上要么相似，要么不相似；其中不相似样本进一步被细分为四种不同的语义变化子类型。作者在通用知识、生物医学、金融、生物学四个领域生成了对应的基准数据集，并对多种语义相似度方法进行了系统比较，包括传统NLP相似度评分方法以及“LLM充当判官（LLM-as-a-judge）”的预测方式。实验表明：语义差异的子类型以及应用领域都会显著影响不同方法的表现，没有一种方法在所有场景下都绝对优于其他。本文结果对在评测环节使用LLM-as-a-judge去判断文本语义内容的有效性和局限性具有重要启示。作者公开了代码和数据集。                                                                                                                                     | True         | 这篇工作核心是围绕“如何更可靠地评估大模型输出的语义正确性”展开，并非单纯的算法创新，而是通过知识图谱自动构造语义相似度基准，系统比较各类语义相似度方法（包括 LLM-as-a-judge）。和你的研究方向的关联主要体现在：<br/>1）AI+运维（SRE）/多智能体系统：无论是多智能体协同决策、智能运维对话系统，还是基于 LLM 的自动化运维助手，最终都要评估“模型给出的自然语言结论是否在语义上正确”。现在大量自动评测工作依赖 LLM-as-a-judge，而本文直接研究了这种评测范式的优缺点，对你在构建自动评估与反馈闭环（如多智能体自博弈、自我修正、自动生成 Runbook/变更建议的质量评测）时非常相关。<br/>2）云原生/AI 系统工程：在云原生环境中集成 LLM 服务时，经常需要自动化测试生成式接口（API 输出的回答正确性、知识问答系统的语义匹配等）。文章给出了一种可自动扩展的基准构造方法，用知识图谱批量生成语义相似/不相似的自然语言对，并区分不同类型的语义差异，对你设计自动化验证流水线（CI/CD 中的语义回归测试、灰度发布前语义健康检查）具有参考价值。<br/>3）与“纯算法”区分：这篇论文并不是提出新的 Transformer 架构或纯推荐算法，而是偏向评测方法与基准构建，更靠近“系统如何可靠使用大模型”的角度，契合你对工程与系统层面问题的兴趣。<br/>综合来看，如果你正在：<br/>- 搭建 LLM 驱动的 SRE/运维助手，需要一种可扩展的语义评测基准；<br/>- 在多智能体系统中用 LLM 做互评、裁决或自动测试；<br/>- 关心 LLM-as-a-judge 是否可靠、在不同领域/语义差异类型下性能如何；<br/>那么这篇文章非常值得深入阅读全文，尤其是其基于知识图谱的基准生成方法和对不同语义相似度方法的系统比较，将有助于你设计更可靠的评估框架和自动化测试体系。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | https://arxiv.org/pdf/2511.19925 |
|    2511.2  | A System-Level Taxonomy of Failure Modes in Large Language Model Applications                                                            | 大语言模型应用中系统级失效模式的分类研究                           | 大语言模型（LLM）正快速融入各类决策支持工具、自动化工作流和AI驱动的软件系统中，但其在生产环境中的行为仍缺乏系统性理解，其失效模式也与传统机器学习模型明显不同。本文从系统工程视角提出了一个面向实际LLM应用的系统级失效模式分类法，总结了十五类隐性失效模式，包括多步推理漂移、潜在不一致性、上下文边界退化、错误工具调用、版本漂移以及由成本约束导致的性能崩塌等。基于该分类，作者分析了当前评估与监控实践中的缺口：现有基准主要度量知识与推理能力，对稳定性、可重现性、漂移监控和工作流集成等系统层面问题关注不足。论文进一步讨论了在生产环境部署LLM时面临的挑战，如可观测性受限、成本约束、模型更新引发的回归等，并提出构建可靠、可维护且具成本意识的LLM系统的一些高层设计原则。通过将LLM可靠性问题从“模型中心”转向“系统工程中心”，本文为后续在评估方法、AI系统鲁棒性以及可依赖的LLM部署方面的研究奠定了分析基础。                                                                                                                                                                                                                 | True         | 这篇论文明显偏向系统工程和生产部署层面的研究，而不是纯算法或模型结构创新，非常契合你在云原生、AI+运维(SRE)、多智能体系统和操作系统相关方向对“AI系统可靠性与工程实践”的关注。论文聚焦的是：LLM在实际软件系统和自动化工作流中以组件形式被调用时，会产生哪些系统级隐性失效模式，以及如何从观察、监控、评估与系统设计原则层面提升可靠性、可维护性与成本可控性。对你而言有价值的点包括：1）系统级失效模式的分类：诸如多步推理漂移、上下文边界退化、工具调用错误、版本/配置漂移、成本驱动性能退化等，都直接对应你在云原生环境中部署和演进LLM服务时可能遇到的运行时问题。这能帮你建立一个更系统化的“故障语言”和问题空间，用于后续做SRE实践、监控体系设计和故障注入/演练。2）评估与监控缺口分析：作者强调现有基准测试无法反映生产中的稳定性、可重现性和工作流集成问题，这与SRE视角下“可观测性”和“可靠性指标”的关注高度契合，可以启发你在云原生+LLM场景下设计新的运行时指标（如漂移度量、工作流级SLA、版本回滚判据等）。3）生产部署挑战与设计原则：包括可观测性不足、成本约束带来的架构权衡、模型升级引发回归等问题，这些都与云原生架构设计（服务拆分、灰度发布、回滚策略、限流与降级等）紧密相关，有利于你思考“LLM系统的SRE化标准实践”。4）多组件/多智能体角度：虽然文中不一定强调多智能体算法本身，但它关注的是LLM在复杂工作流、工具链调用中的行为，这与多智能体系统中“多个LLM/工具协同执行任务”的工程问题接近，有助于你在设计多agent系统的监控、调度和故障隔离策略时借鉴其失效模式框架。总体来看，论文不涉及你不喜欢的纯算法、推荐、CV、Transformer新结构等内容，而是强烈偏向系统级和工程实践，和AI+运维、云原生环境中的LLM系统可靠部署高度相关，值得你继续深入阅读，特别适合作为你后续设计监控指标、SLO/SLA、演化策略和架构模式的理论与概念基础。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | https://arxiv.org/pdf/2511.19933 |
|    2511.2  | M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation                | M$^3$Prune：用于高效多模态多智能体检索增强生成的分层通信图剪枝方法         | 近年来，多模态检索增强生成（mRAG）通过为多模态大语言模型（MLLM）接入外部知识，在多种任务上取得显著效果。同时，研究表明，多智能体间的协作和通信可以明显优于单一模型。然而，多智能体系统在实际应用中通常带来大量 token 开销和较高计算成本，给大规模部署带来挑战。为此，本文提出一种新颖的多模态多智能体分层通信图剪枝框架 M$^3$Prune，通过对多模态多智能体通信图进行分层稀疏化和剪枝，消除不同模态间冗余边，从而在任务性能与 token 开销之间取得更优平衡。具体来说，M$^3$Prune首先对文本和图像等模态分别进行模态内图稀疏化，识别对任务求解最关键的通信边；随后在此基础上构建动态通信拓扑结构，进行跨模态图稀疏化；最后通过逐步剪枝冗余边，得到更高效且层次化的通信拓扑。大量在通用和领域特定 mRAG 基准上的实验表明，相比单智能体和现有鲁棒多智能体 mRAG 系统，该方法在显著降低 token 消耗的同时，持续取得更优的任务表现。                                                                                                                                                                                              | True         | 这篇文章与我们的研究方向高度契合，尤其体现在多智能体系统与高效推理/运维层面的交集。其核心不是提出新的 Transformer 算法或推荐算法，而是关注多模态多智能体 RAG 系统在通信结构上的优化，目标是减少 token 消耗与计算成本，在保证甚至提升效果的前提下降低系统开销。这与云原生和 AI+运维(SRE)中强调的资源效率、可扩展性和大规模部署场景高度一致。对我们而言有几方面价值：1）多智能体系统：论文直接面向多智能体协同决策，通过图稀疏化和拓扑剪枝构建更高效的通信结构，这对我们设计多智能体调度、协作、任务分解框架有参考意义，尤其是如何从“全连接高成本”转向“结构化、层次化通信”。2）AI+运维和成本控制：多智能体 mRAG 在实际部署中容易出现 token 暴涨、推理延迟和资源浪费的问题，M$^3$Prune 提出的分层剪枝框架可以给出一套可借鉴的思路，用于在运维层设计“通信预算控制”“跨模态调用限制”“动态拓扑调整”等策略，有助于面向生产环境的成本优化。3）系统视角与云原生：尽管文中主要是算法与实验，但其所针对的问题本质是“多模型多模态服务之间的通信开销与结构设计”。在云原生环境下，当我们以微服务或多 Agent 服务形式部署 MLLM/mRAG 时，如何利用图结构剪枝和层次化拓扑进行路由与调度，是可以进一步工程化的方向。因此可以将其中的图剪枝思想迁移到服务网格或多 Agent orchestration 层面。4）操作系统/系统结构思考：层次化通信拓扑与传统 OS/分布式系统中的层次总线、分级缓存和路由策略有一定类比意义，有助于从系统架构角度思考“智能体间消息传递的结构化”。需要注意的是，论文包含一定算法与图稀疏化技术细节，但主旨并非纯算法或单纯模型结构改进，而是面向多模态多智能体 RAG 系统通信效率的系统级优化，与我们的多智能体与 AI+运维方向关联紧密。因此建议继续深入阅读，重点关注其通信图建模方式、剪枝策略如何与 token 开销/性能做权衡，以及是否有可迁移到工程系统和云原生平台的指标与机制。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | https://arxiv.org/pdf/2511.19969 |
|    2511.2  | Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design                                                    | 通过推测式算法-系统协同设计降低大模型搜索智能体的延迟                    | 基于大模型（LLM）的搜索智能体在复杂任务上表现出色，但由于每一步都需要串行的“推理—工具调用”流程，整体时延很高。本文从推测执行的视角重新审视这一瓶颈：传统的“预测-验证”式推测虽然能一定程度打破串行执行，但保留了全部原始工作量，还额外增加推理开销，收益有限。作者观察到，智能体早期很多步骤只是简单的信息收集，此时往往可以在不进行完整推理的情况下较准确地预测出下一步动作。基于这一点，论文提出 SPAgent，一个面向搜索智能体的推测式算法-系统协同优化框架，目标是显著降低端到端延迟。在算法层面，SPAgent 设计了两阶段自适应推测机制，在“安全”的情况下有选择地跳过验证以减少不必要的推理。在系统层面，引入了双层调度器，根据底层推理引擎负载动态调节推测请求，避免推测过度导致的资源浪费和抖动。作者在真实系统中实现并评测了 SPAgent，在多种实验场景下实现了最高约 1.65 倍的端到端提速，同时保持甚至略微提升任务准确率，表明该方案有助于多步搜索智能体的实际部署与落地。                                                                                                                                                                               | True         | 这篇论文与“云原生 + AI + 运维(SRE) + 多智能体系统”的研究方向契合度较高，理由如下：<br/><br/>1. 领域相关性：<br/>- 论文研究的是 LLM 驱动的多步搜索智能体的端到端延迟优化，本质是面向实际系统部署的性能/调度问题，而不是纯算法或模型结构创新，和你偏好的系统/运维、而非纯算法研究方向相吻合。<br/>- 提出的 SPAgent 是明显的“算法-系统协同设计”，包含调度、资源管理、推测执行策略等内容，这些理念可以迁移到云原生推理服务、Agent 平台及多智能体编排系统中。<br/><br/>2. 与云原生和SRE的潜在结合点：<br/>- 论文里提到的“二级调度器”和根据引擎负载动态调节推测请求，本质上就是一种面向 LLM 推理/Agent 工作流的智能资源调度策略，这与云原生环境中的弹性伸缩、队列管理、负载感知等非常接近。<br/>- 你在做 AI+运维 时，往往需要优化多 Agent 或复杂推理链路的吞吐与延迟；该工作给出了一个实践可行的框架（自适应推测 + 负载感知调度）和实验数据，可为你在生产级系统中做 SLA 设计、服务编排、排队调度策略提供灵感和可复用思路。<br/><br/>3. 与多智能体系统、操作系统思路的关系：<br/>- 多步搜索智能体在某种程度上可以看作“单体 agent 内部的多阶段任务调度”，其调度问题和多智能体之间的任务分配、工具调用编排在方法论上是相通的。论文中的推测式执行和选择性验证，可以参考扩展到多 Agent 间的并行查询、冗余调用、结果合并等。<br/>- 负载感知调度、推测执行、验证与回滚的思想与传统操作系统中的 speculative execution、任务调度、资源竞争控制有较强类比价值，有助于从系统视角重新设计 LLM/Agent 平台。<br/><br/>4. 不属于你不喜欢的“纯算法”类：<br/>- 虽然涉及推测策略设计，但重点不是新的 Transformer 结构、推荐算法或 CV 模型，而是在真实系统中如何调度 LLM 调用与工具调用，属于系统与工程导向的 AI 研究。<br/>- 实验指标突出“端到端加速”和在真实系统中的部署效果，说明有很强的工程与系统实践价值，而不是纸上谈兵的算法 benchmark。<br/><br/>综合来看，如果你关注以下方向，这篇论文值得细读：<br/>- 如何通过推测执行、任务切分和调度策略降低多步 Agent 工作流的 P95/P99 延迟；<br/>- 如何在云原生或分布式环境中为 LLM/Agent 推理服务设计负载感知调度与资源控制策略；<br/>- 如何把操作系统/调度的经典思想迁移到 LLM 多智能体平台。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://arxiv.org/pdf/2511.20048 |
|    2511.2  | "Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents                                           | “结束了吗？”：面向自主电脑操作智能体的视觉判官与任务完成评估                | 计算机使用智能体（Computer Use Agents, CUAs）旨在自主操作各类数字界面，但在实际应用中往往难以及时、可靠地判断任务是否已经完成。本文提出一个基于视觉语言模型的自主评估与反馈框架，仅依赖屏幕截图和任务描述来判断任务完成情况。作者构建了覆盖 42 个 macOS 内置应用、共 1260 个由人工标注的任务数据集，场景多样。实验表明，该框架在任务成功检测方面可达 73% 的准确率，并在引入评估器反馈后，使整体任务成功率平均相对提升 27%。研究表明，基于视觉的任务完成评估可以作为一种有效的反馈机制，提升自主电脑操作智能体的可靠性和自纠错能力。                                                                                                                                                                                                                                                                                                                                             | True         | 这篇论文和我们的研究方向有较强关联，主要体现在以下几个方面：<br/>1. 云原生与AI运维（SRE）：<br/>   - 文中研究的是“Computer Use Agents”，本质是通过智能体自动操作桌面/应用界面，并通过视觉语言模型判断任务是否完成。这类技术路线与“AI辅助运维/自动执行运维控制台操作”的场景很接近，比如利用智能体自动操作云管理平台、监控控制台、工单系统等，再通过截图+任务描述自动判断是否执行正确，可直接映射到 AIOps/SRE 场景的闭环自动化和安全执行校验。<br/>   - 所提出的“任务完成判官”可以看作是运维自动化流程的一个独立校验组件，有利于构建更可靠的自动运维流水线，对我们在“AI+运维”中设计具备自检、自纠错能力的自动化系统具有参考价值。<br/><br/>2. 多智能体系统：<br/>   - 论文对“评估器/判官”这一角色进行了独立建模：一个负责执行任务的 CUA，一个负责观察结果并给出反馈的判官模型。本质上是多智能体协同中的“执行-监督/审计”模式，对我们在多智能体系统中设计监督代理、审计代理、控制代理的交互架构有直接启发。<br/>   - 实验显示通过判官智能体反馈可以显著提高整体任务成功率，说明在多智能体系统中将“评估/控制智能体”作为一等公民是有效的，这与我们关注的多智能体编排、自治与控制非常契合。<br/><br/>3. 操作系统/人机交互层面：<br/>   - 工作面向的是 macOS 上 42 个内置应用的通用操作，这更接近“操作系统层的通用电脑使用代理”，而不是纯算法或模型结构创新。如何在操作系统/桌面环境中感知状态（截图）、抽象任务、判断完成与否，这些都是 OS 与智能体结合时会遇到的核心问题，对我们从操作系统视角看 AI 代理具有借鉴意义。<br/><br/>4. 不属于你不喜欢的“纯算法”方向：<br/>   - 文章重点在于框架设计、任务建模、数据集构建及通过视觉语言模型实现实践闭环，而不是提出新的大模型结构、新的推荐算法或CV模型。视觉语言模型仅作为工具，不是论文的研究重点，整体偏工程和系统方法，因此不会落入你不喜欢的纯算法/纯模型创新那类工作。<br/><br/>综合来看，该论文围绕“利用视觉语言模型对智能体桌面操作进行任务完成判定和反馈”的系统机制展开，直接对应 AI 代理、自动化操作、评估反馈闭环、可靠性提升等问题，与我们在云原生环境中的 AI+运维自动化、多智能体协作和 OS 级智能体方向高度相关，建议深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | https://arxiv.org/pdf/2511.20067 |
|    2511.2  | VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis | VICoT-Agent：一种用于可解释多模态推理与可扩展遥感分析的视觉交织式思维链智能体框架 | 当前遥感图像分析任务正在从传统的目标识别转向更复杂的智能推理，对模型的推理能力以及调用多种工具的灵活性提出了更高要求。为此，作者提出了一种新的多模态智能体框架——视觉交织式思维链框架（VICoT）。该框架通过在思维链（Chain-of-Thought）中动态引入视觉工具，实现显式的多轮推理。借助基于栈的推理结构以及模块化、兼容 MCP 协议的工具套件，VICoT 使大语言模型能够高效执行具有强泛化能力的多轮、视觉与语言交替的推理任务。作者还提出了“推理栈蒸馏”方法，用于将复杂的 Agent 行为迁移到小型、轻量级模型上，在显著降低复杂度的同时保持推理能力。多项遥感基准实验表明，VICoT 在推理透明度、执行效率和生成质量方面显著优于现有的 SOTA 框架。                                                                                                                                                                                                                                                                                            | True         | 这篇工作虽然应用场景是遥感图像分析，但核心贡献在于多模态智能体框架设计和可解释推理机制，而不属于你不喜欢的纯算法、CV 模型结构或推荐算法方向。几个点与您的研究方向有较强相关性：<br/>1）多智能体 / 智能体框架：论文提出了一个基于栈的推理结构和工具调用机制，本质上是对 LLM Agent 执行流程与状态管理的系统化设计。它强调多轮推理、显式工具调用以及模块化工具套件（且标明 MCP 兼容），这些对多智能体系统设计、任务分解以及 Agent 间协作模式具有借鉴价值。<br/>2）AI+运维（SRE）与工具编排思路：栈式推理结构和工具套件调度方式，与在运维场景中利用 LLM 调度多种运维工具、脚本和监控接口有一定类比性。你可以参考其对“多轮推理＋工具调用轨迹可解释”的设计理念，迁移到故障诊断、自动化变更、复杂运行状态分析等场景，帮助构建可审计、可追踪的 AIOps Agent 工作流。<br/>3）与云原生和操作系统方向的潜在接口：<br/>- 工具套件的模块化、MCP 兼容设计，意味着可以较方便地对接不同服务和工具，从理念上可以类比云原生微服务环境中对多服务能力的统一编排；<br/>- 栈式推理结构是一种类似“系统调度/任务栈管理”的抽象，对你在 OS / runtime 层面设计用于智能体的执行环境时，有一定参考价值，比如如何管理 Agent 的上下文、子任务栈和资源调用顺序。<br/>4）轻量化与迁移到小模型：他们提出的“推理栈蒸馏”，关注如何把复杂 Agent 行为迁移到小模型，这与资源受限环境下的智能运维、边缘侧 Agent 部署等有现实意义。对于云原生环境中的边缘节点、sidecar 或轻量级控制平面 Agent，可参考这类蒸馏思路减少资源占用。<br/>整体来看，这篇论文不是在卷新的 Transformer 结构或视觉检测算法，而是围绕“多模态 Agent 如何组织推理过程与工具调用”展开，偏系统化的框架和工程设计思路，和你在多智能体系统、AI+运维及云原生场景中构建智能 Agent 平台的工作有一定方法论上的共性和借鉴意义，因此建议继续深入阅读，重点关注其栈式推理机制、MCP 工具体系设计以及推理行为蒸馏方法。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | https://arxiv.org/pdf/2511.20085 |
|    2511.2  | From data to concepts via wiring diagrams                                                                                                | 通过接线图从数据提取概念                                   | 接线图是一类带标记的有向图，用于表示诸如时间过程等抽象概念。本文提出了“准骨架接线图”这一概念，并证明准骨架接线图与偏序集的Hasse图之间存在对应关系。在此理论基础上，作者设计了从序列数据中自动抽取接线图的算法。实验中，作者将算法应用于分析一个在电脑游戏环境中自主智能体的行为数据，算法能够正确识别出智能体的获胜策略。作者还将主算法与基于标准聚类方法（DBSCAN和层次聚类）的两种算法进行对比评估，并考察了在数据被扰动时的鲁棒性。整篇工作综合使用了范畴论、图论、聚类、强化学习与数据工程等技术，旨在构建从原始序列数据到高层抽象概念（策略、过程结构）的桥梁。                                                                                                                                                                                                                                                                                                                                                | True         | 这篇工作虽然有较强的理论色彩（范畴论、图论和Hasse图），但总体目标是从序列数据自动抽取“概念性结构”（接线图），并已经在强化学习智能体玩游戏的行为数据上做了验证，本质上是在做“从数据到结构化因果/策略图”的自动抽象。这与传统你不喜欢的那类“纯算法：推荐、Transformer新结构或CV模型”有明显区别，它更偏向知识表示、序列行为建模与策略分析，而不是卷积/注意力架构调参或纯数学优化。 <br/><br/>从你的研究兴趣看：<br/>1）AI+运维(SRE)：如果将运维日志、事件流、告警序列看成时间序列数据，这类从序列中抽取“接线图”的方法有潜在应用：例如自动发现系统状态转换、故障传播路径、常见恢复策略模式等，帮助构建可解释的运维知识图谱或策略流程图。虽然本文实验场景是游戏中的自主智能体，但方法本身较通用，序列→图结构→策略解释的范式对AIOps中复杂事件序列建模有参考意义。 <br/>2）多智能体系统：接线图和Hasse图形式上适合表达多步交互、依赖关系和部分序的因果结构。虽然论文目前只提到单个自主智能体，但如果将多智能体交互日志输入算法，有可能抽取出多智能体协作/对抗策略的结构化表示，理论上与多智能体行为分析、策略解释有较强契合度。 <br/>3）云原生与操作系统方向：论文本身并未直接面向分布式系统、操作系统或云原生平台，但你可以类比：微服务调用链、调度决策、资源状态迁移的日志也是“序列数据”。若你在做可观测性、系统行为建模或策略自动发现（如自动伸缩策略、调度策略）、从trace/log中自动提取状态机/流程图等，这种从序列到抽象有向图的思路是可迁移的。不过，文章不会给你容器、K8s或OS级实现细节，它更像是提供一种抽象建模和算法视角，可为你在系统行为建模方面提供理论和方法论启发。 <br/><br/>需要提醒的是：<br/>- 文章混合了较重的数学构造（范畴论、准骨架、Hasse图），如果你希望找到直接可用到生产环境云原生/运维平台的工程落地方案，这篇更偏概念框架与原型算法。<br/>- 若你当前阶段重点是工程实现（如K8s调度器增强、SRE平台架构、多智能体在集群上的调度）而不是行为抽象/策略解释模型，那么这篇可能显得“过于理论”。<br/><br/>综合来看，如果你的研究中包含：用AI方法自动理解复杂系统的行为序列、自动抽取策略/流程/状态机、做可解释策略分析或为多智能体/运维系统构建结构化行为模型，那么这篇值得细读，重点关注其从序列数据构造接线图的算法部分及在强化学习智能体上的应用。若你的当前重点仅是工程层面的云原生架构或系统实现，这篇的直接收益会相对有限，但依旧可以作为行为建模和策略抽象方面的思路储备。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://arxiv.org/pdf/2511.20138 |
|    2511.2  | Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning                                                | 面向选择性多模态大模型遗忘的良性记忆擦除方法研究                       | 多模态大语言模型（MLLM）在能力上表现出色，但容易无意间记忆并泄露隐私敏感信息。现有“遗忘/反训练”方法虽能去除这类知识，却往往造成整体图像理解能力下降，难以实现“良性遗忘”。为此，本文提出雕刻式记忆遗忘适配器（Sculpted Memory Forgetting Adapter, SMFA），通过将遗忘范围限制在特定记忆区域，以尽量保持模型整体能力。具体而言，SMFA首先对模型进行微调，使其在涉及敏感数据时输出拒答，从而获得一个“记忆遗忘适配器”；随后引入基于保留锚点的掩码机制，引导遗忘过程只作用于相关参数区域，避免对无关知识和通用理解能力造成干扰。为了系统评估选择性多模态大模型遗忘效果，作者构建了首个同时衡量“敏感知识清除”和“一般视觉理解保持”的基准数据集 S-MLLMUn Bench。大量实验表明，相比已有方法，SMFA能够在更精确和可控的前提下实现遗忘，同时维持模型的基础图像理解能力。                                                                                                                                                                                                                    | False        | 这篇工作属于多模态大模型在隐私和“遗忘”（unlearning）方向的研究，重点在于针对敏感信息进行选择性遗忘，同时保持图像理解能力。其技术核心是：在多模态大语言模型上构造一个“遗忘适配器”，通过微调和掩码机制去控制特定记忆区域的参数更新，并提出相应的评测基准。整体上，这是偏模型训练与安全性的算法与评测研究，突出点在于：如何在不显著损伤整体图像理解能力的前提下删除特定知识。 <br/><br/>和你的研究方向的关系：<br/>- 云原生、AI+运维（SRE）：论文没有涉及模型在云原生环境中的部署、资源调度、监控与可观测性、模型在运维体系中的安全管控策略等系统层面的问题，仅停留在训练与评测方法层面，因此关联较弱。<br/>- 多智能体系统：文中聚焦单个多模态大模型的参数级“遗忘”，并未讨论多智能体协作、代理间知识共享或者在多智能体架构中的知识管控策略，直接相关性不强。<br/>- 操作系统方向：没有涉及内存管理、进程隔离、硬件/OS级安全机制或调度策略等操作系统问题，仅是对模型内部表示“记忆”的抽象，并非真正的计算机系统内存管理。<br/><br/>虽然它在“隐私、安全”和“模型能力控制”方面有一定启发意义，但从你的明确偏好看：你不喜欢算法向的大模型方法创新，而本文主要贡献点仍然是一个新的适配器结构和掩码机制，以及一个评测基准，典型偏算法与评测框架。缺少面向云原生运维体系、系统架构或OS机制的内容。因此，从实用价值和研究方向契合度考虑，我不建议投入时间深入阅读全文，如有需要可之后只快速浏览其方法概要，对“模型选择性遗忘”的概念有个宏观了解即可。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://arxiv.org/pdf/2511.20196 |
|    2511.2  | Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025                                                        | 由大语言模型驱动的交互式 AI NPC：CPDC 2025 挑战技术报告           | 本文是 MSRA_SC 团队在 Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025) 竞赛中的技术报告，主要面向游戏/互动场景中的人格化对话式 AI NPC。作者提出了一个统一适用于 GPU Track 和 API Track 的简单而有效的框架。核心有两部分：1）上下文工程（Context Engineering），通过动态工具裁剪（dynamic tool pruning）和人物设定裁剪（persona clipping）进行输入压缩，并配合参数归一化、函数合并等后处理技术以及人工精修的提示词，从而提高工具调用的稳定性、执行可靠性以及角色扮演的连贯性和一致性；2）在 GPU Track 中，使用 GRPO 训练，用强化学习替代传统的 SFT，直接基于奖励信号进行优化，以缓解小样本过拟合并提升面向任务的对话表现。该方案在最终评测中取得了多个赛道前列的成绩，证明了所提出方法在具有人设与常识约束的对话式 AI NPC 任务上的有效性。                                                                                                                                                                 | False        | 从你的研究兴趣来看，你更关注云原生、AI+运维(SRE)、多智能体系统以及偏操作系统/系统软件方向的内容，而不喜欢偏「纯算法」或特定应用领域（如推荐、视觉）的小改进。这篇论文虽然属于 cs.AI 方向，但主要是面向游戏或交互式场景的角色扮演型对话 NPC，技术重点在：<br/>1）围绕 LLM 的对话任务做上下文工程（工具裁剪、persona 压缩、prompt 设计、后处理稳定性等），本质是对特定竞赛任务的提示工程和工具调用策略优化；<br/>2）在 GPU 赛道中用 GRPO 这类 RL 方法替代 SFT，以奖励信号优化对话质量，属于对大模型在垂直任务上做强化学习微调；<br/>3）论文是一个竞赛技术报告，侧重点在流水线设计与经验性调优，而不是系统层面、云原生部署、可观测性、调度、资源管理、MLOps、AIOps 或多智能体协作机制。<br/><br/>与您的方向的关系：<br/>- 云原生 / AI+运维(SRE)：文中没有涉及大规模在线部署架构、服务编排、容器化、弹性伸缩、服务治理、监控告警、日志/指标/链路的可观测性、故障恢复、SLO/SLA 保障等，也没有围绕 LLM 服务化、推理服务调度、成本优化、GPU 资源管理等展开，基本与 SRE/云原生实践关联较弱。<br/>- 多智能体系统：虽然有工具调用和对话代理，但本工作是单一大模型代理在任务中的工具调用链优化，不涉及多智能体之间的协作、博弈、任务分解/分配、角色间通信协议、协调机制、调度策略等典型 MAS 研究问题。<br/>- 操作系统方向：没有涉及内核、调度、资源隔离/管理、存储/网络子系统、异构硬件管理、系统级优化等操作系统相关内容。<br/><br/>综合来看，这篇文章更多是针对“人格化对话 NPC + 工具调用 + 竞赛策略”的工程经验总结，对你的核心研究方向（云原生 AI 系统、AIOps/SRE、多智能体系统、OS 级系统设计）支撑有限，复用价值较低，因此不建议投入时间深入阅读。如果你将来专门做“LLM 驱动的交互式代理产品化落地”（特别是游戏或对话型应用）的子方向，可以再回来参考其上下文工程和 RL 调优思路。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | https://arxiv.org/pdf/2511.20200 |
|    2511.2  | CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents                                                             | CostNav：一种面向具身智能体的成本感知导航评测基准                   | 现有的导航基准大多只关注任务成功率等技术指标，而忽视了在商业场景中至关重要的经济可行性问题，限制了自动配送机器人等具身智能系统的真实落地。本文提出 CostNav，这是一个“微导航经济测试平台”，用于在更贴近真实业务运营的前提下，通过成本–收益分析对具身智能体的导航能力进行综合评估。CostNav 建模了从硬件购置、训练开销、能源消耗、维护成本到按服务等级协议收取的配送收入在内的完整经济生命周期，并基于行业数据设定参数。作者证明了：优化导航任务成功率与优化商业部署收益在本质上是不同的目标，传统导航研究与真正的商业可行性之间存在显著鸿沟。在缩放到现实配送场景的投影下，基线系统在 SLA 遵从率为 43.0% 的情况下仍不具备商业可行性：单次任务亏损约 30.009 美元，且不存在有限回本点，其中 99.7% 的每次任务成本来源于碰撞导致的维护费用，凸显了碰撞规避作为优化重点的重要性。作者实现了一个基于学习的端侧导航基线，并指出 CostNav 可用于评价规则导航、模仿学习和成本感知强化学习等多种导航范式，为从技术指标走向经济指标提供统一的评测框架，从而支撑关于不同导航方案经济权衡的数据驱动决策。                                                                                                                | False        | 这篇文章的核心贡献是为自动配送机器人等具身智能体提出一个“带经济模型的导航基准”，主要服务于机器人导航与具身智能商业落地的研究。它重点关注导航成功率与实际商业可行性（硬件成本、能耗、维护、碰撞成本、SLA 收益等）之间的差异，属于具身智能与机器人应用评测方向。与你的研究兴趣（云原生、AI+运维、多智能体系统、操作系统）相比：<br/>1）它没有涉及云原生架构、分布式系统、调度、容器化或服务网格等基础设施问题，也没有在云环境中大规模部署智能体的系统设计与实践。<br/>2）AI+运维（SRE）相关内容很少，尽管“成本、SLA”这些概念与运维领域在语义上接近，但文章并未讨论系统可靠性工程、故障检测、监控告警、资源自动伸缩或智能运维决策，而是聚焦单机器人/少量机器人在导航任务中的经济收益评估。<br/>3）多智能体系统方面，它并非在做复杂的多智能体协同、任务分配、博弈或大规模智能体调度，而是更偏向单体具身智能体导航的基准，最多是对不同导航策略和训练范式的比较，和你关注的通用 MAS 框架或基础机制联系有限。<br/>4）操作系统层面几乎没有内容，没有涉及系统调用、调度、资源隔离、安全机制或面向智能体的 OS 设计，仅是一个仿真测试平台与经济模型。<br/>整体来看，这篇工作是“具身智能导航+经济可行性分析”的交叉应用研究，更适合机器人导航和自动配送业务建模的研究者。除非你近期有明确计划做“面向商业成本的智能体基准平台”或“机器人服务的经济性建模”，否则对你的主线方向帮助有限，因此不建议投入太多时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | https://arxiv.org/pdf/2511.20216 |
|    2511.2  | Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints                                 | 融合领域知识和因果约束的可操作多样反事实解释方法                       | 反事实解释通过给出达到期望模型输出所需的最小更改，提升机器学习模型的可操作可解释性。然而，现有方法往往忽略真实数据中的复杂依赖关系，从而产生不现实或难以操作的修改。本文在邮件营销网络安全应用场景的驱动下，提出一种生成“多样、可操作且受领域知识约束”的反事实解释方法（DANCE）。该方法在生成反事实时显式融合特征依赖关系和因果约束，以保证反事实在现实世界中的可行性与合理性。具体而言，方法可以从数据中自动学习线性和非线性约束，也可以融合专家提供的依赖图，确保生成的特征修改符合真实业务规则。算法在优化中兼顾可行性、多样性和稀疏性，弥补了现有算法在这几个方面的不足。作者基于与波兰最大邮件营销公司 Freshmail 的联合研发项目，在真实业务场景中设计并验证方法，并在140个公共数据集上进行了广泛实验，结果表明其生成的反事实解释在意义性和领域相关性方面优于现有方法。论文附带源代码以支持结果复现。                                                                                                                                                                                                                         | False        | 这篇工作聚焦于机器学习模型的反事实解释生成，从算法层面改进“可操作性、多样性以及遵守因果/领域约束”的权衡，本质上属于可解释AI与算法/模型层面的研究。虽然它提到了网络安全和邮件营销这样的应用场景，但核心贡献是一个通用的反事实生成算法框架及其在多数据集上的效果验证。与您的核心方向——云原生、AI+运维(SRE)、多智能体系统、操作系统——的直接关联度较弱：<br/>1）它没有涉及云原生架构、Kubernetes、服务弹性、可观测性或运维工作流，不属于AIOps/可观测运维的典型研究；<br/>2）没有面向SRE场景的事件根因分析、告警降噪、容量规划或自动化修复等问题，只是一般性的模型解释；<br/>3）没有多智能体系统的协作决策、分布式智能或系统层调度与资源管理内容；<br/>4）也不涉及任何操作系统内核、调度、资源隔离、IO/存储管理等系统层技术。它更偏向于“智能决策模型如何给出符合领域约束的反事实解释”的算法与方法论，和推荐系统、风控、营销等领域的数据科学/可解释性问题更接近。如果您当前没有在做“针对运维或云原生系统的可解释AI/因果分析框架”这样的具体子课题，这篇文章对您现阶段的研究启发有限，因此整体上不建议投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | https://arxiv.org/pdf/2511.20236 |
|    2511.2  | SMoG: Schema Matching on Graph                                                                                                           | SMoG：基于图的模式匹配框架                                | 模式匹配是数据集成中的关键任务，尤其在医疗领域，需要将不同的电子健康档案（EHR）系统映射到标准模型（如 OMOP CDM）。近年来，大语言模型（LLM）被尝试用于模式匹配，但存在幻觉问题以及领域知识更新滞后等缺陷。知识图谱（KG）通过提供结构化、可验证的知识被视为重要补充。然而现有将 KG 与 LLM 结合的方案往往依赖复杂、多跳查询，或者高成本的向量检索存储。本文提出了 SMoG（Schema Matching on Graph）框架，借鉴知识图谱问答（KGQA）中的成功策略，通过迭代执行简单的 1-hop SPARQL 查询来完成模式匹配。该方法一方面能生成便于人工验证的查询路径，提高可解释性与可靠性；另一方面通过直接查询 SPARQL 端点，显著降低存储需求。在真实医疗数据集上的实验结果表明，SMoG 在性能上可与当前最先进方法相媲美，同时在效率和资源占用方面具有优势，验证了其在知识图谱增强模式匹配任务中的有效性。                                                                                                                                                                                                       | False        | 这篇文章聚焦在“知识图谱增强的模式匹配”问题，具体是针对医疗领域 EHR 到标准数据模型（OMOP CDM）的 schema matching。它的问题背景是数据集成与语义对齐，方法上是把知识图谱和 LLM 结合，设计一种基于简单 1-hop SPARQL 查询的框架 SMoG，以替代复杂多跳查询或高成本向量检索。整体属于数据集成/知识图谱/语义匹配方向，而不是云原生、AI+运维、多智能体或操作系统相关。 <br/><br/>从你的研究兴趣看：<br/>- 云原生/AI+运维：文章没有涉及系统架构、云原生基础设施、SRE 场景下的故障定位、日志分析或运维自动化，仅是知识图谱上的 schema matching 算法设计与实验。<br/>- 多智能体系统：没有涉及多智能体协作、任务分解或智能体编排，更多是单一模型+知识图谱查询框架。<br/>- 操作系统：不涉及 OS 内核机制、资源管理、调度、隔离等系统层问题。<br/><br/>虽然使用了 LLM 和知识图谱，看上去与“知识增强大模型应用”有一定联系，但其贡献核心在于：如何用迭代 1-hop SPARQL 查询提高医疗 schema matching 效果与可解释性。这属于典型的数据管理/知识图谱应用问题，非常垂直在医疗数据集成场景，并没有明显转化到你关心的云原生 AI 运维、系统级 AI 协同或 OS 方向的系统性设计。除非你正好要做“医疗数据平台的数据标准化/集成”或“LLM+KG 驱动的结构化数据对齐”，否则深入阅读对你的主线研究帮助有限。因此总体判断不建议作为重点继续阅读。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://arxiv.org/pdf/2511.20285 |
|    2511.2  | Improving Language Agents through BREW                                                                                                   | 通过 BREW 提升语言智能体能力                              | 基于大语言模型的智能体越来越多地被用于需要结构化推理、工具调用和环境适应的任务，例如数据处理、多步规划和自动化电脑操作。但现有通过 PPO、GRPO 等方法直接优化模型权重的训练范式，在轨迹收敛上的计算开销较大，而且得到的策略难以解释、难以调整和增量改进。为此，本文尝试将智能体与环境交互获得的“经验”组织成可结构化的知识库，并通过构建和迭代优化这类知识库来提升智能体的下游任务能力，提出了 BREW（Bootstrapping expeRientially-learned Environmental knoWledge）框架。BREW 的核心是：将智能体记忆进行有效分区，以提高检索和改进效率；利用任务评分器和行为规范（rubrics）从交互日志中抽取可复用的经验洞见，并结合状态空间搜索来对抗自然语言描述中固有的噪声和模糊性。通过在 OSWorld、τ²Bench 和 SpreadsheetBench 等真实世界、贴近应用场景的基准上实验，BREW 在保持与基础模型相当计算成本的前提下，实现了任务精度提升 10–20%，API/工具调用次数减少 10–15%，从而带来更快的执行时间。与以往将记忆仅视作静态上下文的工作不同，作者将知识库构建为一种模块化、可控的智能体优化“基底”，可以以透明、可解释和可扩展的方式显式调控智能体行为。                                             | True         | 这篇文章与您的研究方向高度相关，尤其是云原生环境中的 AI+运维（SRE）、多智能体系统以及与操作系统交互的自动化代理。理由如下：<br/>1）与 AI+运维 / 云原生的契合度：文中重点研究的是基于 LLM 的智能体在复杂、工具密集的环境中的任务执行优化，例如多步规划、工具/API 调用、环境适应性等。实验基准包括 OSWorld、SpreadsheetBench 等，这类环境和我们在云原生系统里调度脚本、管理服务、操控 CLI/GUI 工具进行运维操作的场景十分接近。BREW 通过构建可控知识库，减少冗余工具调用、提升任务精度和执行效率，这和 SRE 场景下希望降低自动化操作成本、提升可靠性和效率的目标高度一致，可为构建“可学习运维知识库 + 智能体”的体系提供直接思路。<br/>2）与多智能体系统的关联：文章虽然主要是单智能体优化，但核心思想是把环境交互经验沉淀为结构化知识，并通过任务评分器和行为规范进行迭代优化。这一套方法可以自然推广到多智能体系统中：不同智能体共享或分区使用知识库，通过统一的 rubrics 优化协作策略，有利于设计多智能体运维协作、自治服务编排等方案。因此其中的“记忆分区、知识库结构化、可控行为塑形”等机制对多智能体架构设计有较高参考价值。<br/>3）与操作系统方向的联系：OSWorld 等基准本身就涉及对操作系统环境的程序化使用和自动化操作，相当于在“操作系统 + 工具”这一底层环境之上构建智能体控制层。BREW 将智能体与环境交互行为抽象为可解释的知识，使得对 OS 级别任务的策略可以模块化维护与迭代，有助于你在“OS 作为多智能体/智能体平台”的研究思路上借鉴其经验抽取与知识组织方法。<br/>4）工程与系统性强，而非纯算法：文章没有在大模型架构或 Transformer 算法本身做复杂改造，也不是纯推荐或纯 CV 算法，而是围绕智能体训练范式、经验记忆管理、知识库构建与检索、状态空间搜索和任务评分机制等进行系统设计，更偏工程和系统优化。这与您不喜欢单纯算法推导、偏理论的方向形成鲜明对比，更接近可落地的系统方法论，对构建云原生 AI 运维平台、智能代理框架等有实际启发。<br/>综合来看，BREW 提供了一种“通过可解释、可控知识库来持续优化 LLM 智能体”的新思路，非常适合作为你在 AI+SRE、多智能体运维代理、OS 级自动化智能体平台设计时的参考，因此建议认真阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | https://arxiv.org/pdf/2511.20297 |
|    2511.2  | Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries                                        | 利用数据增广从输入输出查询中逆向工程神经网络权重的技术研究                  | 本文研究如何在“教师-学生”框架下，通过对神经网络的输入输出查询来逆向推断其内部权重参数。传统做法是收集教师网络在原始训练数据上的映射，然后训练学生网络去模仿该输入输出函数。但当教师网络参数量远大于训练样本数量时，学生网络容易对查询数据过拟合，而不能真正对齐教师的参数与内部表示。作者系统探索了多种数据增广策略，以更好地采样教师网络的输入输出映射，希望通过精心设计的查询激活教师网络隐藏层中更丰富的表征。实验发现，常规的数据增广方式（如旋转、翻转、加噪声等）对权重识别帮助有限。为此，作者提出了一系列针对神经网络隐藏表征空间专门设计的新型增广方法，用于更充分地“探测”网络内部表示结构。结果表明，这些新增广技术显著扩展了在给定查询样本规模下可被成功恢复的网络规模范围，使得在训练样本数量远少于模型参数数量（最多可少100倍）时，仍能有效恢复网络权重。                                                                                                                                                                                                                                                 | False        | 这篇工作主要关注的是从黑盒神经网络的输入输出映射中逆向推断其内部权重参数，核心贡献在于提出更有效的数据增广策略，用于提升这种“模型偷窃/逆向工程”任务的精度和可扩展性。本质上是一个模型可识别性与表示重构问题，研究重心在神经网络表征空间采样和数据增广设计上，属于比较典型的算法与模型安全/模型提取方向。 从你给出的兴趣点来看，你关注的是云原生、AI+运维（SRE）、多智能体系统和操作系统方向，而明确不喜欢偏“纯算法”的工作。这篇论文： 1）没有涉及云原生基础设施、容器编排、服务治理、分布式系统工程等内容； 2）与AI+运维的关系较弱，虽然模型逆向在安全领域有潜在意义，但论文并没有从运维可观测性、系统可靠性、自动化故障排查或AIOps场景来展开； 3）与多智能体系统、智能体协作或调度机制几乎没有关联； 4）也不涉及操作系统机制（调度、内存管理、IO、隔离等）或系统级架构设计。 文章主要贡献集中在：如何通过特定增广策略更好地“探测”单个网络内部的隐含表示，以便在查询次数有限的情况下提高权重恢复精度。这种工作更靠近模型安全、模型提取攻击以及神经网络可逆性与可解释性等领域，工程侧的系统问题、云原生环境下的部署与运维并不是研究重点。 因此，从你强调的研究方向和对“纯算法/模型侧”论文的不偏好来看，这篇论文与当前研究兴趣的直接重合度较低，如果你不是在做模型安全或模型提取防御相关工作，就不太值得投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | https://arxiv.org/pdf/2511.20312 |
|    2511.2  | Active Inference in Discrete State Spaces from First Principles                                                                          | 从第一性原理出发的离散状态空间主动推理研究                          | 本文旨在澄清“主动推理”（Active Inference）的概念，并将其与自由能原理（Free Energy Principle）解耦。作者在离散状态空间场景下，重新从第一性原理推导主动推理的形式，将其实现过程中的优化问题表述为一类带约束的散度最小化问题，并表明这些问题可以通过标准的平均场（mean field）方法求解，而无需依赖“期望自由能”这一概念。文章指出：当用于建模“感知”时，文中提出的“感知/行动散度准则”与变分自由能是一致的；当用于建模“行动”时，该准则与传统的期望自由能泛函不同，而是多了一个熵正则项。整体上，论文聚焦于主动推理的理论基础与优化形式的统一表达。                                                                                                                                                                                                                                                                                                                                     | False        | 这篇论文主要是从理论和数学角度，对主动推理与自由能原理之间的关系进行澄清与重构，核心贡献在于：用约束散度最小化与平均场方法，重写主动推理的感知与行动优化准则，并从第一性原理层面给出统一的解释。这属于较偏基础的推理与决策理论工作。虽然和人工智能、决策、强化学习等方向概念相关，但论文聚焦的是理论框架与优化形式本身，并未围绕云原生架构、AI+运维(SRE)、多智能体在工程系统中的协作机制、操作系统中的资源管理、调度或系统设计等展开，也没有面向大规模分布式系统、生产级运维、自治运维平台等场景的落地讨论。从摘要看不到与多智能体系统工程实现（如多Agent协同运维、资源调度、容错控制）或云原生环境下智能决策系统的具体连接，更像是认知/控制理论上的通用建模与推断方法研究。如果你目前主要关注系统层面的问题（如云原生基础设施中的智能调度、自主运维Agent框架、OS级智能资源管理、多智能体SRE系统设计），这篇文章的直接启发会比较有限，需要你对主动推理理论有强兴趣且愿意投入较多时间做理论消化和再抽象，才能间接转化为对运维和系统设计的思路。因此，从你的研究方向和实际偏好出发，我不建议作为优先阅读的论文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | https://arxiv.org/pdf/2511.20321 |
|    2511.2  | NNGPT: Rethinking AutoML with Large Language Models                                                                                      | NNGPT：用大语言模型重思AutoML                           | 构建可自我改进的人工智能系统是当前AI领域的重要挑战。本文提出了NNGPT，一个开源框架，将大语言模型（LLM）转化为用于神经网络开发的自我改进AutoML引擎，主要面向计算机视觉任务。与以往框架不同，NNGPT通过生成新的网络模型来扩展神经网络数据集，并在“生成—评估—自我改进”的闭环系统中对LLM进行持续微调。它在一个统一的工作流中集成了五个基于LLM的子管线：零样本网络结构合成、超参数优化（HPO）、具备代码感知能力的精度/早停预测、基于检索增强生成的范围封闭式PyTorch模块合成（NN-RAG）、以及强化学习。基于带有可复现指标的审计语料库LEMUR数据集，NNGPT可从单个提示词生成并验证网络结构、预处理代码和超参数，端到端执行并从结果中学习。通过PyTorch适配层，NNGPT在框架上具有通用性，并展现出较强性能：NN-RAG在1289个目标上实现了73%的可执行率，3-shot提示在常见数据集上显著提升精度，哈希去重机制节省了大量运行开销。一次性预测性能可以匹配基于搜索的AutoML，大幅减少试验次数；在LEMUR上的HPO达到RMSE 0.60，优于Optuna的0.64，而代码感知预测器实现RMSE 0.14、皮尔逊相关系数0.78。该系统已自动生成超过5000个通过验证的模型，展示了NNGPT作为自治AutoML引擎的可行性。作者计划在论文接收后开源代码、提示词和模型以支持复现与社区使用。 | False        | 这篇工作核心是利用大语言模型构建一个面向神经网络（主要是计算机视觉任务）的自我改进AutoML框架。其主要贡献集中在：让LLM生成网络结构和PyTorch代码、进行超参数优化、代码执行可行性预测和性能预测，并通过闭环强化学习提升模型生成能力，本质上是“LLM辅助的模型搜索与HPO系统”。<br/><br/>从你的研究兴趣来看：<br/>- 云原生：文中没有涉及分布式基础设施、云原生调度、Kubernetes 集成、弹性扩缩容、云上资源编排等内容，更多是在一个实验数据集（LEMUR）和PyTorch环境中做AutoML实验，没有云原生工程方面的系统设计或运维特性。<br/>- AI+运维（SRE）：虽然它有自我改进和自动化实验的“闭环”概念，但针对的是神经网络架构搜索与训练，不是服务可靠性、故障检测、日志分析、容量规划或运维自动化等方向，也没有多集群运维、可观测性、告警等SRE主题。<br/>- 多智能体系统：体系架构虽然包含多个LLM管线（架构合成、HPO、代码预测等），但并不是多智能体协同决策或通信框架，而是单一LLM驱动的多步pipeline，没有多Agent交互、协调机制或MAS理论与工程实现。<br/>- 操作系统方向：没有讨论资源管理、调度算法、内核机制、隔离/安全、IO/存储管理，甚至也未针对系统层的训练调度或执行优化，仅在AutoML实验级别描述。<br/><br/>它和你不喜欢的方向却比较接近：<br/>- 工作重点是自动化神经网络架构搜索和超参数优化，强调AutoML在视觉任务上的效果，本质偏向模型与算法层面，而非系统或运维工程。虽然不是纯新Transformer结构设计，但仍然属于模型性能/搜索优化领域。<br/>- 且主要面向计算机视觉数据集和网络结构，进一步偏离你的兴趣重点。<br/><br/>如果你在做“LLM 驱动的 AutoML 平台”、“LLM 生成训练脚本并自动执行”的云原生化落地，可能可以借鉴其：<br/>- LLM生成可执行训练代码并自动验证的方式；<br/>- 基于闭环反馈持续微调LLM以改进代码/配置生成质量的思路；<br/>- hash 去重等减少实验次数的工程手段。<br/>但当前摘要并未说明任何与云原生调度、分布式训练平台、LLM Ops、MLOps/SRE 落地相关的内容，也未讨论系统扩展性、可靠性或多Agent协作机制。因此，从你的明确兴趣和排斥点出发，我建议将此文归为“可做参考但不必优先深入阅读”，只在你以后要搭建 LLM 驱动 AutoML 工具链时再回头快速浏览其实现细节。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | https://arxiv.org/pdf/2511.20333 |
|    2511.2  | VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning                             | VibraVerse：面向物理一致多模态学习的大规模几何-声学对齐数据集           | 理解物理世界需要建立遵循物理定律而非仅依赖统计相关性的感知模型。然而，现有以视觉与语言为主的多模态学习框架往往缺乏物理一致性，也忽视了物体的几何形状、材料属性、振动模态与其发声之间的内在因果链。本文提出 VibraVerse，一个大规模几何-声学对齐数据集，显式刻画了从三维几何 → 物理属性 → 模态参数 → 声学信号的因果链。每个三维模型均包含明确的物理属性（密度、杨氏模量、泊松比）及体素化几何表示，并据此计算模态本征频率和本征向量，用于在受控激励下进行碰撞声音合成。为保证多模态间的一致性，作者提出了 CLASP 对比学习框架，用于跨模态对齐，并保持物体物理结构与声学响应之间的因果对应关系。该框架在统一的表示空间中对形状、图像与声音进行物理一致的对齐，使每个样本都可追溯到其控制方程并具备良好的可解释性。基于 VibraVerse，论文构建了几何到声音预测、声音引导的形状重建以及跨模态表示学习等一系列基准任务。大量实验表明，在 VibraVerse 上训练的模型在跨模态任务中具有更高的精度、可解释性及泛化能力。VibraVerse 被确立为一个物理一致、因果可解释的多模态学习基准，为基于声音的具身感知和更深层次理解物理世界提供了基础。数据集将对外开源。                                                                                  | False        | 这篇工作本质上是一个以几何-声学为核心的多模态数据集与对比学习框架研究，主要关注三维几何、物理材料参数、振动模态与声学信号之间的因果一致性和多模态表示学习。它更偏向于物理建模 + 多模态表征 + 对比学习，在应用上面向具身感知、机器人感知、图形与视觉/听觉理解等方向。 <br/><br/>从你的研究兴趣来看：<br/>- 你关注云原生、AI+运维(SRE)、多智能体系统、操作系统方向，偏系统与工程、智能体协作或AI在运维中的应用。<br/>- 你明确不喜欢偏“纯算法”，尤其是推荐算法、Transformer 新结构、CV 等。 <br/><br/>这篇文章虽然在广义上属于人工智能和多模态学习，但：<br/>- 主要贡献是数据集构建和物理多模态建模，与云原生架构、运维自动化、SRE 实践、系统软件或多智能体协作机制几乎没有直接联系。<br/>- 没有涉及分布式系统、资源调度、服务可靠性、可观测性、AIOps、智能体在系统层面的协同控制等问题。<br/>- 更适合做具身智能、机器人感知、图形/渲染、声音合成或物理感知的研究者阅读。 <br/><br/>除非你计划在未来研究“具身智能体在真实物理世界中的多模态感知”（例如机器人运维、物理环境中的多智能体协作，以及声音作为额外观测信号的使用），否则这篇文章对你当前的研究主线参考价值有限。因此从你现有研究方向出发，我认为不必投入时间深入阅读，只需知道它代表了物理一致多模态学习的一类趋势即可。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | https://arxiv.org/pdf/2511.20422 |
|    2511.2  | DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs                                                  | DRAFT-RL：面向强化学习增强型大模型的多智能体“草稿链”推理框架            | 大语言模型（LLM）在多步推理上已有突出表现，近期工作提出了多智能体反思框架，通过多个LLM智能体相互批判和改进彼此输出，并结合强化学习进行优化。然而，这类方法通常依赖单次回答，缺乏在推理过程中的结构化多样性探索。本文提出DRAFT-RL，一种将“草稿链”（Chain-of-Draft, CoD）推理机制与多智能体强化学习训练相结合的新框架。与生成单一回答不同，每个智能体在同一查询下会生成多个“草稿”推理轨迹，随后由其他智能体和学习到的奖励模型进行评估，选择最有前景的推理路径。这些被选中的草稿用于更新智能体的策略，通过actor-critic式的强化学习训练，不断改进未来的推理策略。DRAFT-RL实现了显式的多路径探索、同伴引导式反思以及与奖励对齐的选择过程，使LLM智能体的行为更稳健且更易解释。作者在代码生成、符号数学和知识密集型问答等复杂推理任务上评估了该方法，相较于现有的反思式和强化学习式智能体，在推理准确率和收敛速度上都有显著提升。                                                                                                                                                                                             | True         | 从元信息看，这篇文章集中在“多智能体+LLM+强化学习”的推理框架上，属于多智能体系统和智能体编排/训练的范畴，而不是单纯的算法（例如Transformer新结构或纯推荐算法）或视觉CV方向。它的核心贡献是：在多智能体LLM框架中，引入类似Chain-of-Thought但更结构化的多草稿推理（Chain-of-Draft），再用多智能体互评和奖励模型进行强化学习训练，从而提高复杂任务中的推理能力和稳定性。 <br/>和你的研究方向的关系：<br/>1）多智能体系统：该工作本质上是一个多LLM智能体协作与互相反思的框架，涉及多智能体交互、策略更新和协调机制，与“多智能体系统”研究方向高度相关，尤其是如果你关注的是智能体间协作、自治决策和协同推理。 <br/>2）AI+运维（SRE）/云原生：虽然论文评测任务主要是代码生成、符号数学和知识问答，但其提出的多智能体推理+RL训练范式，有潜力迁移到运维场景（如多Agent协同做告警诊断、变更评估、自动化故障处理），在这些场景中你也需要“多路径推理+互评+奖励反馈”的机制来提高决策可靠性和可解释性。因此该框架可以作为设计云原生AI运维多Agent系统时的重要方法论参考。 <br/>3）与操作系统方向的潜在交叉：如果你在做“AI增强的操作系统/自治运行时管理”或“智能体驱动的调度与资源管理”，这类多Agent协作和策略学习框架可以为设计自治控制平面或调度Agent体系提供思路，尤其是如何通过多草稿、多轨迹试探和反馈来改进决策策略。 <br/>4）不是你不喜欢的纯算法方向：这篇工作更偏向系统化的多智能体框架与训练范式，而不是在Transformer结构或推荐算法上做微小改进，也与CV无关，符合你不喜欢领域的排除条件。 <br/>综上，如果你想在云原生或SRE场景中设计多智能体LLM系统（例如用于智能运维、自动诊断与决策），或在操作系统/系统管理层面探索多Agent自治控制，这篇论文在方法和框架思路上具有较强参考价值，值得继续深入阅读，重点关注其多草稿推理的设计、奖励模型构造、以及多智能体协同与RL训练的整体架构，看是否可以迁移到你关注的AI+运维和多智能体场景中。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | https://arxiv.org/pdf/2511.20468 |
|    2511.2  | Universe of Thoughts: Enabling Creative Reasoning with Large Language Models                                                             | 思维宇宙：让大语言模型具备创造性推理能力                           | 基于大语言模型（LLM）的推理能力因为在数学和复杂逻辑任务中的突出表现而备受关注。从链式思维（CoT）提示开始，大量推理方法涌现，它们通常将问题分解为较小的、顺序的思维步骤。然而，现有工作多集中在“常规问题求解”，并不真正关注如何通过“创造性推理”生成具有创新性的解决方案。在解空间巨大且常规方案往往次优的领域（如药物发现、商业策略制定等），具备发现创新方案的创造性推理尤为关键。为此，本文首先基于认知科学中的既有理论提出一个计算化的创造性推理框架；在该框架下，作者定义了三类核心创造性推理范式：组合式（combinational）、探索式（exploratory）与变革式（transformative）推理，为系统性探索“思维宇宙”以生成创新方案提供方向。进一步地，作者给出了在LLM中实现该框架的一组具体方法，称为“思维宇宙”（Universe of Thoughts, UoT），分别对应上述三类创造性过程。最后，作者构造了三个需要创造性问题求解的新任务，并提出一个评测基准，从可行性（作为约束）、效用和新颖性三个正交维度衡量创造性表现。实验表明，相比现有最先进的推理技术以及具备推理能力的商业模型，UoT在创造性推理方面取得了更优的表现。                                                                                            | False        | 这篇工作主要是围绕大语言模型在“创造性推理”上的方法和评测框架展开，核心贡献是：从认知科学中抽象出三种创造性推理范式，并设计一套Prompt/推理流程（Universe of Thoughts）让LLM在开放式任务上更具创造性，然后通过新任务和基准来验证其生成结果在可行性、效用和新颖性上的优势。整体上，这是一个偏通用推理与创意生成能力的研究。 <br/><br/>从你的研究兴趣来看：<br/>- 云原生、AI+运维（SRE）、多智能体系统、操作系统方向：本文并未涉及系统架构、调度、资源管理、容器/集群、Observability、自动化运维流程、故障自愈、SRE实践，也没有多智能体框架、协议或协作机制设计，更没有OS级机制或内核/运行时相关内容。它也没有面向工程实践的落地场景（如AIOps、故障诊断、自动编排等），而是停留在抽象的推理流程与思维模式层面。 <br/>- 它属于更偏“通用大模型推理与创意生成框架”的方法学工作，不是纯算法（例如Transformer结构改进、优化器、推荐算法等），但研究重心仍在如何设计新的推理范式和评测任务上，而不是系统层次或运维自动化。 <br/><br/>如果你当前的工作重点是：<br/>- 搭建云原生/分布式系统中的智能运维代理、多智能体协作系统，或<br/>- 在SRE场景中用LLM做日志分析、根因定位、变更决策、故障演练、容量规划等，<br/>那么这篇论文对你日常工作与工程设计的直接帮助有限，更偏概念和通用能力。你如果希望寻找能直接指导系统设计、Agent编排、调度策略或云原生平台集成的大模型运维方案，这篇的“转化效率”不高。 <br/><br/>因此，我不建议将其列为优先深入阅读对象。若你未来想设计一个“更有创意”的AI助手或策略生成代理（比如为SRE提出新的缓解方案组合），可以在有余力时回来看其创造性推理框架的思想，但不需要现在投入大量时间。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | https://arxiv.org/pdf/2511.20471 |
|    2511.2  | Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic                                                          | 高保真合成网络流量的隐私影响量化研究                             | 为解决网络流量数据稀缺及隐私风险问题，近年来出现了大量用于生成合成网络流量的生成模型。然而，合成流量并不天然具有隐私保护能力，其泄露敏感信息的程度及衡量方法仍缺乏系统研究，且不同模型架构在流量表示与生成方式上的差异，使问题更加复杂。本文提出了一套面向合成网络流量的综合隐私评估指标体系，将成员推断攻击（MIA）、数据提取攻击等通用隐私攻击方法与网络特定标识符、属性等特征结合，用于量化隐私泄露风险。基于这些指标，作者系统评估了多类代表性生成模型在不同数据集上的脆弱性，并分析影响攻击成功率的关键因素。结果显示，各模型和数据集的隐私风险差异显著：MIA 成功率从 0% 到 88% 不等，生成流量中可恢复的网络标识符比例最高可达 100%，暴露出严重的隐私隐患。进一步分析表明，训练数据多样性以及模型对训练数据的拟合程度等对攻击效果有重要影响。研究最终为如何设计与部署隐私泄露更小的合成网络流量生成模型提供了实践指导，为安全生成和共享网络流量数据奠定了基础。                                                                                                                                                                                            | True         | 这篇论文与云原生和AI+运维/SRE方向高度相关，原因有几点：1）研究对象是网络流量数据及其合成生成模型，这与云原生环境中常见的流量采集、可观测性、流量回放与测试、AIOps 异常检测数据密切相关；2）很多云原生运维和SRE场景为了做智能告警、异常检测、容量规划，会使用真实网络流量训练模型或进行仿真测试，而生产数据往往涉及用户隐私和敏感业务信息，合成流量是常见的替代方案，这篇工作直接聚焦“合成网络流量是否真的隐私安全”，能为你在生产/测试环境中如何生成、发布或使用流量数据提供系统性的安全评估框架和设计指南；3）文中引入针对网络场景的隐私度量与攻击方法（如成员推断、数据提取结合网络标识符恢复），可以帮助你在云原生多租户环境下、以及多智能体系统基于流量数据协同（如多智能体做流量调度、入侵检测、自动化运维决策）时，评估使用生成数据可能带来的隐私风险；4）如果你在做AI+运维平台或自动化SRE系统，需要构造合成流量来训练多智能体或运维智能体，这篇论文给出了哪些生成模型风险更高、哪些训练特征会加大隐私泄露等经验结论，对实际工程决策有直接参考价值。论文不属于纯算法或Transformer新结构设计，而是偏向系统实践与安全评估方法，因此非常符合你的兴趣领域，我建议阅读全文，尤其关注其隐私度量指标设计、攻击实验设置及对生产部署的建议部分。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://arxiv.org/pdf/2511.20497 |
|    2511.21 | FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization                                | FRAGMENTA：基于片段的端到端生成模型及智能体调优在药物先导优化中的应用        | 该工作针对药物发现场景下的小样本分子生成问题提出了一个端到端框架 FRAGMENTA。其核心包括两个部分：1）一种新型的分子生成模型，将“分子片段化”重构为“词表选择”问题，并通过动态 Q-learning 联合优化片段划分与分子生成；2）一个“具身智能体（agentic）”的 AI 调优系统，通过与医药化学专家的对话式反馈不断更新目标与约束，从而自动化模型调参，逐步学到领域知识，最终实现从“人-智能体”到“智能体-智能体”的完全自动化调优。实证结果基于真实的癌症药物发现场景，显示 FRAGMENTA 在找到高评分分子数量上显著优于基线，人-智能体配置几乎找到两倍于基线的高分子，而智能体-智能体配置在调参效果上超过传统的人-人调优方案，说明其在捕获专家意图和自动化调优方面的有效性。                                                                                                                                                                                                                                                                               | False        | 这篇论文的主要贡献集中在药物分子生成这一垂直应用场景上：一方面是面向小样本药物数据的分子片段化生成模型（将片段化视作“词表选择”并用 Q-learning 联合优化），另一方面是针对药物化学专家的人机协同“智能体调优”流程。虽然文中使用了多智能体/agentic tuning 的术语，但这些智能体的设计主要围绕药物设计领域的目标建模与对话式反馈收集，属于特定领域的自动调参系统。就你的研究兴趣而言：<br/><br/>- 云原生：论文没有涉及系统部署、云原生基础设施、可观测性、可伸缩调度或分布式系统实现，仅在高层描述“自动化调优流程”，缺乏与云原生平台、Kubernetes、服务网格或云上 MLOps 的紧密联系。<br/>- AI+运维（SRE）：文中的“调优”是模型目标函数与搜索空间的领域调优，并非针对系统运行状态、资源利用率、故障诊断或自愈运维的 AI 应用，也没有可直接迁移到运维场景的监控/告警/决策闭环机制设计。<br/>- 多智能体系统：虽然有“Human-Agent”和“Agent-Agent”的配置，但其智能体更像是任务分解与对话反馈收集的应用级代理，核心创新点不在多智能体协作机制、通信协议、协调算法或 MAS 的理论/系统设计上，而是聚焦药物化学调参流程；如果你关注的是一般性的 MAS 架构、调度与协调，这篇论文可迁移的思想非常有限。<br/>- 操作系统方向：文章没有任何 OS 层面的调度、资源隔离、内核机制或系统级优化内容，也未涉及在 OS 层面支持大规模 Agent 系统或生成模型运行的方案。<br/>- 不喜欢的方向匹配度：工作中使用动态 Q-learning 和生成模型，但整体属于“药物分子生成 + 强化学习 + 专家交互调参”的应用驱动研究；虽然不是推荐系统或 Transformer 结构改进，但仍然可以看作偏算法与应用结合的药物设计工作，对通用系统/运维/云原生很难直接复用。<br/><br/>综合来看，这篇文章的价值主要面向药物发现和分子生成社区，与云原生、AI+运维、多智能体系统（作为基础设施或通用框架）、以及操作系统方向的直接关联较弱。即便其“agentic tuning”思路在其他领域也可类比使用，但论文并未在系统架构、运维自动化或通用多智能体调度上做深入设计或抽象。如果你当前没有做“AI for drug discovery”或“交互式领域专家调参平台”的具体项目，这篇文章不太值得投入时间仔细阅读全文，顶多可略读摘要和方法，了解“通过对话式专家反馈自动调整生成模型目标”的应用思路即可。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | https://arxiv.org/pdf/2511.20510 |
|    2511.21 | Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam                                                                   | 评估大模型在中国执业药师考试中的表现                             | 背景：随着大语言模型（LLM）日益融入数字化医疗教育和考试评估流程，其在高风险、强专业领域资格认证任务中的能力引起关注。在中国，全国执业药师资格考试是衡量药师临床与理论能力的标准化基准。目的：本文比较了两个大语言模型——ChatGPT-4o 与 DeepSeek-R1——在2017–2021年中国执业药师考试真实试题上的表现，并探讨其对AI辅助形成性评价的启示。方法：研究共收集2306道来自正式考试、培训资料及公开题库的单项选择题（纯文本，不含表格和图像），以原始中文形式输入模型，基于答案是否完全正确进行打分。利用Pearson卡方检验比较总体表现，并采用Fisher精确检验分析按年份的多项选择题正确率差异。结果：DeepSeek-R1整体正确率显著高于ChatGPT-4o（90.0% vs. 76.1%，p < 0.001）。在各知识单元层面，DeepSeek-R1同样表现更优，尤其在基础知识和临床综合板块。按年份划分的多项选择题中，DeepSeek-R1也普遍优于ChatGPT-4o，但在单个单元-年份层面差异未达到统计学显著（均 p > 0.05）。结论：DeepSeek-R1在适应执业药师考试的结构和语义需求方面表现出良好的一致性。研究表明，在特定专业场景下，面向领域的模型值得进一步探索，同时也强调在涉及法律和伦理敏感问题时仍需保持人类监管。                                | False        | 这篇文章聚焦在对两个现有LLM（ChatGPT-4o 与 DeepSeek-R1）在中国执业药师资格考试题目上的对比评测，属于典型的领域考试基准测试研究。它的核心贡献是：在医疗/药学教育场景下，从准确率和统计显著性角度比较不同通用与“类本地化/类领域化”模型的表现，并讨论在高风险医疗认证中的使用边界和人类监管必要性。<br/><br/>从你的研究兴趣来看：<br/>- 云原生：文中没有涉及模型在云原生环境中的部署、弹性扩缩、服务编排、观测性或资源管理等内容。<br/>- AI+运维（SRE）：不涉及AIOps、运维自动化、异常检测、日志分析、告警优化、值班排班等运维/SRE相关应用，也没有讨论在生产环境下对LLM服务的可用性、可靠性指标或SLO/SLA。<br/>- 多智能体系统：研究对象是两个独立LLM的静态对比评测，没有多智能体协作、角色分工、自动化工作流或Agent架构设计。<br/>- 操作系统方向：无调度、存储管理、隔离、安全、多租户、系统性能等底层系统问题，也不涉及系统架构和平台层实现。<br/><br/>论文偏应用评测与教育/医疗垂直场景，虽然在广义上属于“AI在行业中的应用”，但它既没有云原生与运维视角，也没有系统架构或多智能体视角，更不讨论工程落地与系统设计，仅停留在考试题对比、统计分析和合规监督层面的讨论。因此，与您的研究方向关联度较弱。<br/><br/>如果你未来要做“LLM在考试/培训系统中的云原生部署与运维方案”、“领域模型在线评测平台的SRE实践”、“多Agent教学辅导系统”等工程课题，这篇文章最多能提供一点业务背景参考（如考试题结构、性能指标基准），但在技术深度和系统设计上几乎没有可借鉴内容。基于你对研究偏好的要求和对纯性能评测类工作的低兴趣，这篇文章整体不太值得你投入时间深入阅读。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | https://arxiv.org/pdf/2511.20526 |
|    2511.21 | Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models                                                    | 超越生成：提升视觉语言模型事实准确性的多跳推理方法                      | 视觉语言模型（VLM）是强大的生成式工具，但由于缺乏稳健的推理能力，常常产生事实不准确的输出。已有研究在大语言模型（LLM）中广泛探索引入外部知识以增强推理，但在VLM领域相关工作仍然有限，并且多模态信息的无缝衔接进一步增加了难度。本文提出了一个面向VLM的知识引导多跳推理框架，利用结构化知识图谱对生成内容进行多步事实核验，并以图像描述任务作为示例进行说明。该方法包括：视觉实体识别、知识图谱遍历以及基于事实的描述修正等步骤，实现系统化的多跳推理。作者使用分层式、三元组式以及要点式等不同知识表示，对其在事实准确性和逻辑推理能力方面的效果进行分析。基于由 Google Landmarks v2、Conceptual Captions 和 COCO Captions 混合构建的精心整理数据集，实验表明该框架可使事实准确率在初步实验中提升约 31%，并揭示了推理模式和失败模式的关键洞见。该工作展示了将外部知识与VLM集成以提升推理能力和可靠性的潜力，为更可靠、更具知识性的多模态系统铺平道路。                                                                                                                                                                        | False        | 这篇文章主要聚焦在视觉语言模型（VLM）的事实性和多跳推理能力，通过引入知识图谱来对图像描述结果进行多步验证和修正。核心贡献点在于：在多模态生成场景中，将结构化知识图谱与视觉实体识别结合，实现事实核验，从而改进图像 caption 的准确性。整体上，它是一个面向多模态生成质量与推理能力的研究，偏多模态算法与知识表示方法论。 <br/>从你的研究兴趣来看：<br/>1）云原生、AI+运维（SRE）、操作系统方向：本工作几乎不涉及系统层面、部署架构、可观测性、运维自动化或资源调度等内容，也没有探讨在云原生环境部署多模态系统的工程问题。<br/>2）多智能体系统：文中是单模型/单框架的知识引导推理过程，不涉及多智能体协作、任务分解、Agent 交互协议或自治协调机制。<br/>3）你不喜欢的纯算法/视觉方向：该论文很明显偏向视觉和多模态推理，构建图像 caption 数据集，评估视觉实体识别和知识图谱三元组、层次结构等表示方式对生成结果的影响，属于典型的多模态算法与事实性提升研究。尽管使用了知识图谱和推理框架，但仍然是围绕 VLM 的模型能力优化，而不是围绕系统、运维或云平台层面的应用与实践。<br/>如果你目前的工作重点是：<br/>- 构建云原生 AI 平台、AI 运维工具链、多智能体运维系统，<br/>- 或探索在操作系统/系统软件层面支持智能体与模型运行，<br/>那么这篇文章与这些方向的直接关联较弱，更多是多模态模型算法层面的探索。除非你正好在研究“如何提升多模态模型在生产环境中的事实性”并考虑借鉴知识图谱式多跳验证思路，否则这篇论文对你当前方向的启发有限，因此整体不建议投入时间深入阅读全文。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | https://arxiv.org/pdf/2511.20531 |
|    2511.21 | PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic                                                 | PaTAS：一种基于主观逻辑的神经网络并行信任传播系统                    | 随着人工智能系统在安全关键领域中的部署，模型的“可信度”成为关键需求。传统评价指标如准确率和精确率难以刻画模型预测的不确定性以及在对抗或退化条件下的可靠性。本文提出并行信任评估系统 PaTAS（Parallel Trust Assessment System），利用主观逻辑（Subjective Logic）在神经网络中建模和传播信任。PaTAS 通过在标准神经网络计算旁路中引入“信任节点”和“信任函数”，在网络中并行传播输入、参数和激活的信任信息。该框架定义了“参数信任更新”机制，在训练过程中动态更新参数可靠性；同时提出“推理路径信任评估（IPTA）”方法，在推理阶段为具体样本计算实例级的信任评分。基于真实世界和对抗数据集的实验表明，PaTAS 能产生可解释、对称、收敛的信任估计，这些估计可补充准确率等指标，并在数据被投毒、存在偏差或高度不确定的场景下揭示模型可靠性缺口。结果显示，PaTAS 能有效区分良性与对抗样本，并识别出模型置信度与实际可靠性不一致的情况。通过在神经网络内部实现可量化、可推理的信任传播机制，PaTAS 为 AI 生命周期中的模型可靠性评估提供了一套系统化、可解释的基础。                                                                                                                | True         | 这篇论文与“云原生、AI+运维、多智能体系统、操作系统”之间的直接工程场景结合不算特别强，但它在“AI系统可信度与可靠性评估”方面提供了一个较系统且可工程化的框架，因此仍然值得你关注，尤其是从“AI+运维（SRE）与多智能体系统的可靠性监控”视角来看。<br/><br/>优点与相关性：<br/>1. 跟你的偏好契合度：<br/>- 这篇工作不是单纯的算法提分或新模型结构，而是面向“模型可靠性和不确定性”的系统级框架（并行信任通路），更偏系统工程与方法论，而不是你不喜欢的纯算法/纯推荐/Transformer 新结构/纯 CV。<br/>- 它强调的是“如何对现有神经网络在推理过程中的信任进行建模与传播”，对生产环境中模型监控、风险控制有潜在实用价值。<br/><br/>2. 与云原生和 AI+运维（SRE）的关系：<br/>- 在云原生环境中部署模型服务时，一个核心问题是：我们如何在实时流量上评估模型输出的“可靠度”，用来驱动流量调度、熔断、灰度发布和回滚？<br/>- PaTAS 提供的并行信任评估通路，可以在理论上作为：<br/>  - 实例级推理“可信度信号”，供 SRE 或控制平面使用，例如：当信任度下降时触发降级、切换模型版本或回退到规则系统。<br/>  - 对抗流量检测信号，用于识别可疑请求（对抗样本、数据分布漂移）并进行路由隔离或额外审计。<br/>- 虽然论文本身未必讨论云原生落地，但你可以从中提炼出可用于：<br/>  - 模型服务侧车（sidecar）中增加“信任评估模块”的设计思路；<br/>  - 在 A/B 测试和灰度发布中，将“信任度指标”纳入 SLO/SLA 或告警基线。<br/><br/>3. 与多智能体系统的关系：<br/>- 在多智能体系统中，不同智能体之间的协作、投票、协同决策，往往需要对“各个智能体或各个模型的可靠度”进行度量与融合。<br/>- PaTAS 使用主观逻辑进行信任建模和传播，本质上在提供一种“如何把单个神经网络内部的各节点信任进行组合和更新”的方法：<br/>  - 你可以借用其信任建模和组合逻辑，扩展到“多智能体之间的信任传播和聚合”，使得多模型/多代理协作过程更有可解释的可靠度量。<br/>  - 对构建“可信多智能体决策系统”，有潜在启发，尤其是当你希望系统在关键决策前有一个“自我置信审计”。<br/><br/>4. 对操作系统/运行时视角的启发：<br/>- 虽然它不是典型 OS 论文，但“并行信任计算通路”的设计理念有一定系统结构上的启发：<br/>  - 将“功能计算路径”和“可信度（元信息）计算路径”解耦并行，可以类比为在运行时中增加一个元数据通路，专门用于安全性/可信度监控。<br/>  - 这对你如果在做“AI 原生操作系统”或“模型感知运行时”的设计时，可作为一种在内核或运行时中管理“模型可信元数据（trust metadata）”的抽象参考。<br/><br/>5. 非纯理论算法，更偏系统性框架：<br/>- 文中涉及主观逻辑和信任传播的数学建模，但是重点在于：<br/>  - 如何在现有神经网络结构上构建并行信任节点与信任函数；<br/>  - 如何在训练和推理阶段把信任度作为一等公民来管理和更新；<br/>  - 实验包括在被投毒、偏置、对抗等现实问题场景上的可靠性评估，而不是单纯追求 benchmark 指标。<br/>- 这更贴近你在实际系统中关心的“部署后如何监控和保证 AI 可靠性”的问题。<br/><br/>不利点（局限）：<br/>- 文章主要是在单模型/单网络层面做信任传播，暂未直接讨论：<br/>  - 分布式多模型服务、多微服务协同或云原生环境中的部署管控；<br/>  - 大规模多智能体协作框架中的信任博弈与任务分配。<br/>- 如果你当前的工作非常偏向“系统实现、调度算法、容器/内核机制”，而对模型内部结构不太愿意深入，则这篇论文会显得偏重模型侧的信任机制，需要一定精力阅读其主观逻辑和网络内部结构设计。<br/><br/>综合判断：<br/>- 从你给出的方向看，它不是一个“完美强相关”的云原生/OS 论文，但在“AI 可靠性、对抗流量识别、在线信任评估”这个子方向上，与 AI+运维、多智能体系统的工程实践关系较大，可以作为构建可观测与可信 AI 系统的理论与方法参考。<br/>- 若你目前有：<br/>  - 在生产环境部署模型并希望增加“可信度评估与告警机制”；<br/>  - 在多智能体系统中需要为每个 agent 的决策增加可解释信任权重；<br/>  - 或在探索“AI 原生基础设施/操作系统”时考虑引入模型信任元数据；<br/> 这篇论文值得你花时间细读和思考如何结合到系统层设计里。 | https://arxiv.org/pdf/2511.20586 |
|    2511.21 | Building a Foundation Model for Trajectory from Scratch                                                                                  | 从零构建轨迹基础模型的实践教程                                | 基础模型正在深刻改变人工智能领域，但如何从零开始构建面向“出行/移动轨迹”的基础模型，目前在社区中还缺乏清晰、系统的文档与教程。本文以教程形式，基于 GPT-2 给出一个最小可运行实现，逐步展示如何将原本的文本语言模型适配到时空轨迹数据，包括数据表示、模型改造和训练流程等具体代码级步骤。作者随后回顾并对比了代表性的轨迹基础模型（如 TrajFM 与 TrajGPT），分析它们在架构设计上的创新点与差异，并引入相关领域的一些补充技术，如 TimesFM 的 patching 方法。文章主要面向研究人员和工程实践者，旨在以实现为中心讲解轨迹基础模型的概念与术语，帮助 SIGSPATIAL 社区更好地构建和评估出行/移动领域的基础模型，从而提升该方向研究的清晰度和评审质量。                                                                                                                                                                                                                                                                                      | False        | 这篇文章本质上是一个面向“轨迹（spatiotemporal mobility trajectories）”的基础模型教学型教程，重点是：如何从 GPT-2 出发，适配并训练一个轨迹数据的 foundation model，并综述 TrajFM、TrajGPT 等轨迹模型以及相关时间序列模型方法。它的核心贡献在于：代码级展示如何把预训练语言模型迁移到轨迹数据，并帮助 SIGSPATIAL（地理空间/移动计算）社区理解和评估轨迹类基础模型。 <br/><br/>从你的研究兴趣来看：<br/>- 你专注于云原生、AI+运维（SRE）、多智能体系统、操作系统等，更偏向系统架构、工程实践与智能运维，而不是具体领域数据建模（如轨迹建模、地理空间 AI）。<br/>- 这篇文章核心是“轨迹数据上的基础模型构建”，属于应用型模型方法论，和云原生架构、运维自动化、多智能体协同或操作系统内核/调度等系统性问题关系较弱。<br/>- 文中虽然涉及 GPT-2 的工程实现细节，但大部分内容会围绕如何表示轨迹、怎样适配时空数据、对比不同轨迹模型架构，方向较偏“领域建模 + 模型工程”，与 AI 驱动运维、SRE 自动化或多智能体系统并不直接相关。<br/><br/>因此，如果你当前工作并未涉及：<br/>- 出行/物流/地图导航/地理位置服务中的轨迹建模，或<br/>- 在云原生环境中大规模部署轨迹模型的具体业务，<br/>那么这篇教程对你的收益会比较有限。它更适合作为轨迹/地理空间 AI 方向入门材料，而不是云原生/AI+运维/多智能体/操作系统领域的关键文献。基于你明确“不喜欢纯算法和与自身方向弱相关的模型文章”的偏好，我建议可以不继续深入阅读。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://arxiv.org/pdf/2511.20610 |
|    2511.21 | Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development                                           | 大型语言模型中的版权检测：一种面向生成式人工智能开发的伦理方法                | 大型语言模型（LLM）的广泛使用引发了训练数据中未经授权包含受版权保护内容的关键担忧。现有检测框架（如 DE-COP）计算开销大，对独立创作者不够友好。随着法律审查力度的加大，亟需一种可扩展、透明且易用的解决方案。本文提出了一个开源版权检测平台，使内容创作者能够验证其作品是否被用于 LLM 训练数据集。该方法在现有方法基础上改进了易用性和相似度检测效果，优化了数据集验证流程，并通过高效的 API 调用将计算开销降低约 10–30%。平台采用直观的用户界面和可扩展的后端架构，有助于提升 AI 开发的透明度和合规性，为负责任的 AI 开发和版权执法相关研究奠定基础。                                                                                                                                                                                                                                                                                                                                            | True         | 这篇文章从工程和系统角度提出了一个面向 LLM 训练数据版权检测的开源平台，强调可扩展后端、计算开销优化（通过高效 API 调用降低 10–30%）、易用的界面和透明流程。虽然主题是“版权检测”，但本质上涉及：1）面向 LLM 的服务化平台设计；2）可扩展后端与性能优化；3）面向独立创作者的 API 化能力与工具链，这些都与云原生和 AI 工程化实践有一定关联。 对你的研究方向来说：1）云原生与运维（SRE）方面，可以参考他们如何设计“可扩展后端”和“计算成本优化”的架构思路，将相似理念扩展到你自己的 AI+运维平台（如模型治理、数据合规性检查服务）上；2）AI 方向上，它体现了“负责任/合规 AI”的一类新型基础设施，可能为你构建面向 LLM 的合规、审计或监控系统提供参考；3）如果你在做多智能体系统或智能运维平台，这种“围绕模型生命周期提供附加服务（检测、审计、溯源）”的架构思路，可以迁移到多智能体系统中的审计、权限和合规模块设计。 文章不属于你不喜欢的纯算法/模型新结构方向，而是偏平台和工程侧，篇幅也只有 4 页，阅读成本较低，值得快速通读，重点关注他们的平台架构、API 设计方式以及如何在精度与计算成本之间做折中，这些都可以为你在云原生 AI 平台、AI+运维工具设计上提供一些启发。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://arxiv.org/pdf/2511.20623 |
|    2511.21 | Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems                                        | 用AI对抗AI：利用基础模型保障AI驱动安全关键系统                     | 随着人工智能组件，尤其是深度神经网络，被广泛集成到航空航天和自动驾驶等安全关键系统中，如何对这类系统进行可靠性与安全性保障成为重大挑战。传统形式化验证与测试方法在面对AI系统的不透明性、以及从高层自然语言需求到底层网络表示之间的语义鸿沟时往往力不从心，同时也受到需求工程长期存在的问题影响，如自然语言规格的歧义性和形式化过程的规模化瓶颈。本文提出利用基础模型（大语言模型和多模态模型）“以AI对抗AI”的方法，从需求到实现构建一条较为完整的保障管线。具体包括两个互补组件：REACT（Requirements Engineering with AI for Consistency and Testing），利用大语言模型帮助从非形式化的自然语言需求自动/半自动推导形式化规格，支持早期的一致性检查与验证；SemaLens（Semantic Analysis of Visual Perception），利用多模态视觉-语言模型对基于DNN的感知模块进行概念级推理、测试和运行时监控，使感知行为更易于用人类可理解的语义来分析和解释。两者结合，为从非形式化需求到经过验证的AI实现提供了一条端到端的技术路线。                                                                                                                 | True         | 这篇论文与您“AI+运维(SRE)、多智能体系统、操作系统和云原生中AI系统的可靠性/安全性保障”的方向有较强交集，值得重点一读。理由如下：<br/><br/>1）研究重点不是纯算法，而是“AI系统的工程化保障”<br/>文章关注的是如何在安全关键系统（航空航天、自动驾驶等）中对AI组件进行需求工程、形式化验证和测试，这更偏系统工程、软件工程与安全保障，而非提出新的模型结构、Transformer变体或推荐算法。这与您不喜欢的“纯算法/模型结构创新”有明显区别，更接近“如何把AI安全可靠地用在复杂系统中的方法论和工具链”。<br/><br/>2）方法与LLM / 基础模型在工程流程中的落地密切相关<br/>- REACT 利用大语言模型：<br/>  - 从自然语言需求生成或辅助生成形式化规格；<br/>  - 做需求的一致性检查和早期验证。<br/> 这与云原生/运维环境中逐渐兴起的“用LLM做需求分析、配置生成、策略验证”的趋势高度类似，可为您在AI辅助SRE、自动化配置与策略验证、运行时约束生成等方面提供思路。<br/><br/>- SemaLens 利用多模态模型对DNN感知模块进行语义级测试和监控：<br/>  - 将底层感知输出映射到人类可理解的语义上；<br/>  - 用于运行时监控和解释。 <br/>  这种“用基础模型做语义监控”的思想可迁移到多智能体系统和云原生服务中，例如利用LLM/VLM对复杂系统行为做语义级健康检查、异常解释、策略合规性检测等。<br/><br/>3）对AI+运维(SRE)和云原生安全保障的启发<br/>虽然论文聚焦的是航空航天和自动驾驶等安全关键领域，但核心问题是“AI系统如何从需求到实现实现可验证、可监控和可解释的安全保障”。这种端到端的保障链条在以下方面具有可迁移性：<br/>- 对云原生微服务和AI推理服务，如何：<br/>  - 从自然语言SLO/SLA或合规要求生成形式化策略或监控规则；<br/>  - 用LLM协助验证配置、策略与需求之间的一致性；<br/>  - 用基础模型在运行时对系统行为进行高层语义监控与异常检测。<br/>- 对AI驱动的运维和多智能体运维系统：<br/>  - 如何给“智能体行为”定义可形式化的需求，并通过LLM辅助验证；<br/>  - 如何用大模型对多智能体系统的交互进行语义分析和风险评估。<br/>这些都可以直接借鉴该文的思路和架构，只需将安全关键控制系统替换成云原生基础设施和运维场景。<br/><br/>4）与操作系统/系统软件方向的关系<br/>论文讨论的保障框架虽然不直接针对OS内核，但其关注点——如何在复杂系统栈中把AI组件纳入可验证、可监控的正式流程——可以为：<br/>- AI增强操作系统（如智能调度、智能资源管理）；<br/>- 基于AI的系统自动化决策模块（如自动伸缩、自动恢复策略）<br/>提供建模和验证思路。例如：用类似REACT的思路从自然语言策略/安全需求生成形式化约束，用类似SemaLens的语义监控来解释系统行为，这些对系统软件和OS层面融入AI具有参考价值。<br/><br/>5）不属于您排斥的“纯算法、推荐、CV”范畴<br/>- 虽然用到了VLM，但重点不是视觉识别本身，而是“如何利用多模态模型作为分析与监控工具”，不属于传统CV算法论文；<br/>- 没有引入新的DNN或Transformer架构，关注的是工程化方法与工具；<br/>- 目标是系统级的安全与保障，而非模型指标上的微小提升。<br/><br/>综合来看，这篇文章在：<br/>- 用LLM/基础模型提升需求工程与形式化验证；<br/>- 用基础模型构建AI系统的语义级测试与监控；<br/>- 端到端AI系统安全保障方法论；<br/>等方面都与您在云原生、AI+运维、多智能体系统和系统软件中对“AI组件可控、可管、可验证”的关注点高度契合，因此推荐深入阅读，尤其是其方法框架和工具设计思路部分。                                                                                                                                                                                                                                                                                                                                | https://arxiv.org/pdf/2511.20627 |
---
# cs.OS
|   arxiv_id | english_title                                                                | chinese_title               | chinese_abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | worth_read   | comment                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | download_url                     |
|-----------:|:-----------------------------------------------------------------------------|:----------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------|
|     2511.2 | SARA: A Stall-Aware Memory Allocation Strategy for Mixed-Criticality Systems | SARA：一种面向混合关键性系统的停顿感知内存分配策略 | 在边缘设备中，由于成本、体积和功耗等限制，其可用内存容量通常较小。有限的内存资源会导致应用之间的内存竞争，并引发不可避免的页面置换，从而带来缓慢的存储 I/O 和显著的性能下降。特别是在混合关键性边缘系统中，低效的内存分配会打破应用性能之间的平衡，使软实时任务无法按时完成（错过截止期），或者使非实时应用无法获得足够吞吐。在高内存和 I/O 压力下，作者还观察到不可预测的长时间系统级停顿（long stalls），进一步恶化性能。为此，本文提出了一种停顿感知实时内存分配器 SARA（Stall-Aware Real-Time Memory Allocator）。SARA 的核心思想是在保证软实时任务在截止期内完成的前提下，仅为其分配“刚好足够”的内存，并尽可能将剩余内存用于提升非实时应用的吞吐量。为将软实时任务的内存占用压缩到最小且仍满足实时约束，SARA 利用基于 PSI（Pressure Stall Information）的新指标来刻画内存不足导致的延迟如何影响每个软实时作业的执行时间，其中作业按周期运行，一个软实时任务由多个周期构成。此外，SARA 根据对“长停顿”的定义在线检测此类事件，并主动丢弃受影响的作业，以降低任务执行过程中的停顿影响。实验结果显示，在仅提供峰值内存需求 60% 的内存容量条件下，SARA 能够实现平均 97.13% 的软实时任务截止期满足率，并在此基础上将非实时应用吞吐量较现有方法最高提升 22.32 倍。 | True         | 这篇论文属于操作系统方向（cs.OS），关注的是边缘设备上的内存管理和调度，在混合关键性（软实时 + 非实时）场景下进行 stall-aware 的资源分配，与纯算法/模型创新无关，因此不触及你不喜欢的纯算法、推荐算法或 CV 领域，而是偏系统与调度机制设计，和你的研究方向有比较紧密的交集：<br/>1）与操作系统方向的关系：<br/>- 核心问题是在内存受限的边缘设备上，如何设计内存分配策略，使得软实时任务在截止期内完成，同时最大化非实时任务吞吐。<br/>- 使用 PSI（Pressure Stall Information）这种 Linux 内核提供的停顿信息作为度量指标，属于典型的 OS 层性能反馈与资源控制的结合，可能涉及 cgroup/memory pressure、调度器与内存管理子系统的联动。<br/>- 若你关注内核级资源管理、调度策略、内存管理优化，这篇工作在机制与策略上都具有参考价值。<br/><br/>2）与云原生和边缘计算的潜在联系：<br/>- 虽然论文场景是“边缘设备”，不是直接面向云原生集群，但边缘侧的资源受限、混合关键性负载（例如某些实时推理任务 + 普通服务）与云原生边缘计算/边缘容器编排的需求高度相关。<br/>- 文中通过动态感知系统 stall、基于 PSI 指标来调整内存分配，这种思路可以迁移到云原生环境中，用于节点级资源控制、Kubernetes 调度策略（例如基于 PSI 做 pod 级资源弹性、QoS 区分）。如果你研究的是“云原生 + 边缘 + 资源调度”，这类 stall-aware 策略是非常值得借鉴的。<br/><br/>3）与 AI + 运维（SRE）、多智能体系统的关系：<br/>- 论文本身没有引入 AI 模型或多智能体，但它提供了一套“根据 runtime 性能信号（PSI、deadlines、throughput）做资源调优”的框架，非常适合作为 AI 运维或自治运维（AIOps）的控制对象。<br/>- 在 AI+SRE 场景中，你可以用智能体/学习算法来决定内存/CPU/IO 配额，而这篇论文给出了一套专注于“混合关键性 + stall-aware”的设计目标与评价指标，可以作为后续 AI 控制策略的基线或对照方案。<br/>- 若你在多智能体资源调度、智能化运维上做研究，可以将 SARA 看作一个“单智能体 rule-based allocator”，然后思考如何扩展为“多节点、多任务、多智能体”的协作优化，这在系统设计和实验方法上有很好的启发。<br/><br/>总体评价：<br/>- 优点：问题典型且工程价值高（边缘设备内存受限、软实时与非实时并存）、方法结合了真实系统指标（PSI、I/O stall）、实验结果有比较明显的性能提升（97% 截止期满足率及 22 倍吞吐提升）。<br/>- 不足：从摘要看主要是策略和系统实现层面的工作，对 AI、智能体本身没有直接内容，如果你当前工作更偏“算法/智能体设计”而非“系统基础设施”，阅读价值会偏应用与启发，而非直接方法贡献。<br/><br/>结合你的研究方向（云原生、AI+运维、多智能体、操作系统），这篇论文在操作系统与边缘侧资源管理方面高度相关，且可以作为未来在云原生/边缘环境中引入 AI 控制策略的坚实系统基础。因此我建议标记为值得深入阅读，重点关注：<br/>- PSI 指标如何采集、建模并用于决策；<br/>- 实时任务与非实时任务之间的资源权衡策略；<br/>- 在高内存与 I/O 压力下对“长停顿”的定义和检测方法；<br/>- 实验平台与评测方法，为你未来在云原生或边缘环境中做类似调度策略和 AI+SRE 评测提供参考。 | https://arxiv.org/pdf/2511.19991 |
---
